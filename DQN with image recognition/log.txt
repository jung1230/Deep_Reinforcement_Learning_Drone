episode:1, reward: -50, mean reward: -9.76, score: -58.53508881726532, epsilon: 0.8855607164166145, total steps: 515
episode:2, reward: -2.7896449785665425, mean reward: -1.42, score: -49.567259052971934, epsilon: 0.8845864640052074, total steps: 550
episode:3, reward: -0.153660911042806, mean reward: -0.95, score: -33.40703367227272, epsilon: 0.8836133475588382, total steps: 585
episode:4, reward: -50, mean reward: -2.95, score: -50.07313849139538, epsilon: 0.8831411004778648, total steps: 602
episode:5, reward: -50, mean reward: -2.6, score: -80.47530682945015, epsilon: 0.8822806326589765, total steps: 633
episode:6, reward: -50, mean reward: -2.82, score: -59.13853329818468, epsilon: 0.8816982400772998, total steps: 654
episode:7, reward: -3.432609668911766, mean reward: -1.18, score: -41.1903657090092, epsilon: 0.8807284912606806, total steps: 689
episode:8, reward: 0.00410417365350213, mean reward: -1.74, score: -60.7385812035634, epsilon: 0.8797598731579696, total steps: 724
episode:9, reward: -0.3858193022233536, mean reward: -0.94, score: -33.039059354564415, epsilon: 0.8787923844507693, total steps: 759
episode:10, reward: -1.234430678044106, mean reward: -0.29, score: -10.25646428022165, epsilon: 0.8778260238222204, total steps: 794
episode:11, reward: 0.6843656655331642, mean reward: -0.86, score: -29.9463896198597, epsilon: 0.8768607899569985, total steps: 829
episode:12, reward: -50, mean reward: -8.14, score: -56.97118761173877, epsilon: 0.8766678782799127, total steps: 836
episode:13, reward: -50, mean reward: -2.81, score: -70.30666580054182, epsilon: 0.8759792753390879, total steps: 861
episode:14, reward: -50, mean reward: -4.62, score: -60.09457497461722, epsilon: 0.8756214285255168, total steps: 874
episode:15, reward: -50, mean reward: -3.5, score: -55.94279853802948, epsilon: 0.8751812144978119, total steps: 890
episode:16, reward: -0.436495262421289, mean reward: -1.09, score: -38.26984027937493, epsilon: 0.8742190644442286, total steps: 925
episode:17, reward: -2.683680518112112, mean reward: -0.45, score: -15.77935612344237, epsilon: 0.8732580362444989, total steps: 960
episode:18, reward: -50, mean reward: -4.37, score: -56.77911326776902, epsilon: 0.8729013683790784, total steps: 973
episode:19, reward: -50, mean reward: -11.62, score: -58.08592132695492, epsilon: 0.872764229579566, total steps: 978
episode:20, reward: -1.869965554158398, mean reward: -0.03, score: -0.979474960283369, epsilon: 0.8718048976974674, total steps: 1013
episode:21, reward: -50, mean reward: -2.71, score: -94.94623917311529, epsilon: 0.8708466843832733, total steps: 1048
episode:22, reward: -50, mean reward: -5.46, score: -54.60090113476454, epsilon: 0.8705731144193392, total steps: 1058
episode:23, reward: -50, mean reward: -2.2, score: -68.26330392468947, epsilon: 0.8697256268117806, total steps: 1089
episode:24, reward: -2.5921424566816427, mean reward: -0.74, score: -25.98637358042282, epsilon: 0.8687698378991104, total steps: 1124
episode:25, reward: -1.4363618937812817, mean reward: -0.73, score: -25.66603659214428, epsilon: 0.8678151634232905, total steps: 1159
episode:26, reward: -50, mean reward: -1.79, score: -55.451000242351626, epsilon: 0.8669705242264952, total steps: 1190
episode:27, reward: -50, mean reward: -1.79, score: -46.62789967464033, epsilon: 0.8662627898347011, total steps: 1216
episode:28, reward: -50, mean reward: -2.89, score: -86.73562505691984, epsilon: 0.8654469350402515, total steps: 1246
episode:29, reward: -50, mean reward: -4.33, score: -56.240745852433776, epsilon: 0.8650936512520832, total steps: 1259
episode:30, reward: -50, mean reward: -8.13, score: -65.06616731489916, epsilon: 0.8648763219236142, total steps: 1267
episode:31, reward: -50, mean reward: -5.74, score: -63.0860681680891, epsilon: 0.8645775887100117, total steps: 1278
episode:32, reward: -50, mean reward: -8.88, score: -53.262507481215465, epsilon: 0.8644146894827354, total steps: 1284
episode:33, reward: -50, mean reward: -6.45, score: -64.46803831445578, epsilon: 0.864143263159808, total steps: 1294
episode:34, reward: -50, mean reward: -4.49, score: -44.85045397906566, epsilon: 0.8638719272972444, total steps: 1304
episode:35, reward: -50, mean reward: -8.27, score: -49.60271968576481, epsilon: 0.8637091691881383, total steps: 1310
episode:36, reward: -50, mean reward: -2.32, score: -44.17153171913489, epsilon: 0.8631939832071004, total steps: 1329
episode:37, reward: -50, mean reward: -4.26, score: -68.23297227756609, epsilon: 0.8627603953830874, total steps: 1345
episode:38, reward: -50, mean reward: -1.8, score: -48.53878636635491, epsilon: 0.8620292400964744, total steps: 1372
episode:39, reward: -50, mean reward: -4.71, score: -51.7905997964929, epsilon: 0.8617315506215114, total steps: 1383
episode:40, reward: -50, mean reward: -9.84, score: -59.01497669058702, epsilon: 0.8615692205449358, total steps: 1389
episode:41, reward: -50, mean reward: -2.61, score: -60.087910848292694, epsilon: 0.8609472559260867, total steps: 1412
episode:42, reward: -50, mean reward: -5.29, score: -89.98529649625044, epsilon: 0.8604878493252255, total steps: 1429
episode:43, reward: -1.0360201922363217, mean reward: 0.41, score: 14.175437898318762, epsilon: 0.8595428315352465, total steps: 1464
episode:44, reward: -50, mean reward: -3.44, score: -65.31211513326139, epsilon: 0.8590302833993162, total steps: 1483
episode:45, reward: -50, mean reward: -4.34, score: -65.11443089556056, epsilon: 0.8586258693695493, total steps: 1498
episode:46, reward: -50, mean reward: -3.19, score: -63.78310014477387, epsilon: 0.8580869651113484, total steps: 1518
episode:47, reward: -50, mean reward: -13.25, score: -53.012162822106546, epsilon: 0.8579792273653429, total steps: 1522
episode:48, reward: -50, mean reward: -5.61, score: -56.11344311200162, epsilon: 0.8577099458389689, total steps: 1532
episode:49, reward: 0.38616315848798877, mean reward: -0.71, score: -24.803642137718356, epsilon: 0.8567681670466077, total steps: 1567
episode:50, reward: -50, mean reward: -2.71, score: -65.06028146330002, epsilon: 0.8561230106099534, total steps: 1591
episode:51, reward: -50, mean reward: -12.5, score: -49.981245829939326, epsilon: 0.8560155347070916, total steps: 1595
episode:52, reward: -50, mean reward: -4.69, score: -75.07282502194099, epsilon: 0.8555857743681918, total steps: 1611
episode:53, reward: 0.7083485986049993, mean reward: 0.08, score: 2.6375842181746805, epsilon: 0.8546464723308251, total steps: 1646
episode:54, reward: -0.4716314090374283, mean reward: -0.93, score: -32.460517332414895, epsilon: 0.8537082655068369, total steps: 1681
episode:55, reward: -50, mean reward: -11.66, score: -58.29271618120069, epsilon: 0.853574325291247, total steps: 1686
episode:56, reward: -50, mean reward: -3.28, score: -49.27062336962294, epsilon: 0.853172638558653, total steps: 1701
episode:57, reward: -50, mean reward: -1.75, score: -59.64925747849844, epsilon: 0.8522628918554617, total steps: 1735
episode:58, reward: -2.067883271302634, mean reward: -0.33, score: -11.538435106670477, epsilon: 0.851327464253833, total steps: 1770
episode:59, reward: -50, mean reward: -3.6, score: -64.86941379402381, epsilon: 0.8508468119853807, total steps: 1788
episode:60, reward: -50, mean reward: -3.47, score: -58.95317630618936, epsilon: 0.8503931273480432, total steps: 1805
episode:61, reward: -50, mean reward: -5.08, score: -45.74532815161464, epsilon: 0.850153045423928, total steps: 1814
episode:62, reward: -3.402623404435161, mean reward: 0.11, score: 4.021547224227106, epsilon: 0.8492200778744934, total steps: 1849
episode:63, reward: -50, mean reward: -2.22, score: -59.98633279265832, epsilon: 0.8485011033914545, total steps: 1876
episode:64, reward: -50, mean reward: -5.24, score: -83.78138179631071, epsilon: 0.8480753496807272, total steps: 1892
episode:65, reward: -50, mean reward: -10.62, score: -63.707449187288546, epsilon: 0.8479157505712339, total steps: 1898
episode:66, reward: -50, mean reward: -4.58, score: -54.96368033580663, epsilon: 0.8475966480957553, total steps: 1910
episode:67, reward: -50, mean reward: -2.45, score: -56.377573788600074, epsilon: 0.846985391677116, total steps: 1933
episode:68, reward: -0.49987813119074076, mean reward: -1.11, score: -38.79484881413785, epsilon: 0.846056117568793, total steps: 1968
episode:69, reward: -50, mean reward: -17.35, score: -52.05375808045417, epsilon: 0.8459765159371839, total steps: 1971
episode:70, reward: -2.3350365184553823, mean reward: -1.06, score: -37.161741214529656, epsilon: 0.8450484181642285, total steps: 2006
episode:71, reward: -50, mean reward: -2.82, score: -64.87529546127243, epsilon: 0.8444391146398315, total steps: 2029
episode:72, reward: -50, mean reward: -2.99, score: -53.76264295700244, epsilon: 0.8439625941414928, total steps: 2047
episode:73, reward: -50, mean reward: -2.62, score: -55.028127959064875, epsilon: 0.843407014801049, total steps: 2068
episode:74, reward: -50, mean reward: -2.33, score: -48.84189576004246, epsilon: 0.8428518242300583, total steps: 2089
episode:75, reward: -50, mean reward: -3.69, score: -66.42955837717466, epsilon: 0.8423762558203103, total steps: 2107
episode:76, reward: -50, mean reward: -1.68, score: -47.17538839691301, epsilon: 0.8416370496647448, total steps: 2135
episode:77, reward: -1.363563527099359, mean reward: 0.37, score: 13.043199706944023, epsilon: 0.8407140116503408, total steps: 2170
episode:78, reward: -0.7003486474635281, mean reward: -1.12, score: -39.19036543274811, epsilon: 0.8397920498856858, total steps: 2205
episode:79, reward: -0.07519453776990304, mean reward: -1.13, score: -39.40181477068538, epsilon: 0.8388711631158873, total steps: 2240
episode:80, reward: 0.7854121357074462, mean reward: -0.78, score: -27.210242752129773, epsilon: 0.837951350087516, total steps: 2275
episode:81, reward: -50, mean reward: -2.47, score: -83.90931270341545, epsilon: 0.8370588444061674, total steps: 2309
episode:82, reward: -50, mean reward: -6.97, score: -55.72114075434371, epsilon: 0.8368489900294862, total steps: 2317
episode:83, reward: -0.8043543229271677, mean reward: -0.2, score: -7.119292281927699, epsilon: 0.8359315348273829, total steps: 2352
episode:84, reward: 0.7974488668365325, mean reward: -0.51, score: -17.83262902712235, epsilon: 0.8350151493655456, total steps: 2387
episode:85, reward: -50, mean reward: -4.75, score: -52.22320289238783, epsilon: 0.8347273632414586, total steps: 2398
episode:86, reward: -50, mean reward: -4.22, score: -59.131481728883074, epsilon: 0.8343612425734128, total steps: 2412
episode:87, reward: -0.43092823729153906, mean reward: -0.65, score: -22.74068966821389, epsilon: 0.8334466880509495, total steps: 2447
episode:88, reward: -0.4447170201218569, mean reward: -1.1, score: -38.33952913438864, epsilon: 0.8325331998865991, total steps: 2482
episode:89, reward: -50, mean reward: -5.95, score: -71.42433769624986, epsilon: 0.8322202492009543, total steps: 2494
episode:90, reward: -50, mean reward: -2.73, score: -51.79048619056397, epsilon: 0.8317249998886301, total steps: 2513
episode:91, reward: -50, mean reward: -7.37, score: -58.981013317959935, epsilon: 0.831516567680856, total steps: 2521
episode:92, reward: 1.7181506701477929, mean reward: 0.17, score: 5.949047662142107, epsilon: 0.8306053300105606, total steps: 2556
episode:93, reward: -50, mean reward: -9.58, score: -47.922166026874635, epsilon: 0.8304752399633639, total steps: 2561
episode:94, reward: -50, mean reward: -4.73, score: -42.56132233360097, epsilon: 0.8302411325092489, total steps: 2570
episode:95, reward: -2.8295294941495115, mean reward: -1.24, score: -43.30555267862675, epsilon: 0.8293313819789867, total steps: 2605
episode:96, reward: -50, mean reward: -3.05, score: -63.99067533018621, epsilon: 0.828786040903246, total steps: 2626
episode:97, reward: -50, mean reward: -4.22, score: -105.58111526393483, epsilon: 0.8281373228725477, total steps: 2651
episode:98, reward: -50, mean reward: -6.73, score: -47.099939755005266, epsilon: 0.8279557786781904, total steps: 2658
episode:99, reward: -50, mean reward: -4.13, score: -74.26826786807658, epsilon: 0.8274891452150214, total steps: 2676
episode:100, reward: -50, mean reward: -3.25, score: -48.69434438347065, epsilon: 0.8271004978123614, total steps: 2691
episode:101, reward: -50, mean reward: -4.55, score: -59.20025311778738, epsilon: 0.8267638272138741, total steps: 2704
episode:102, reward: -50, mean reward: -4.21, score: -58.917948971835386, epsilon: 0.8264014219956354, total steps: 2718
episode:103, reward: -50, mean reward: -2.04, score: -50.91522928912033, epsilon: 0.8257546903195974, total steps: 2743
episode:104, reward: 0.10041558953082586, mean reward: -0.25, score: -8.78374973090692, epsilon: 0.8248501709198036, total steps: 2778
episode:105, reward: -50, mean reward: -2.65, score: -55.721396564268105, epsilon: 0.8243079655941639, total steps: 2799
episode:106, reward: -50, mean reward: -4.71, score: -56.530116516706386, epsilon: 0.823998304344305, total steps: 2811
episode:107, reward: -50, mean reward: -3.75, score: -60.04781009051976, epsilon: 0.8235856153088463, total steps: 2827
episode:108, reward: -50, mean reward: -17.35, score: -52.05318534371523, epsilon: 0.8235082606151146, total steps: 2830
episode:109, reward: -50, mean reward: -2.41, score: -60.21892750925326, epsilon: 0.8228639389026027, total steps: 2855
episode:110, reward: -50, mean reward: -6.71, score: -60.369254783140974, epsilon: 0.8226321144963316, total steps: 2864
episode:111, reward: -50, mean reward: -4.43, score: -75.3884750822952, epsilon: 0.8221944136584003, total steps: 2881
episode:112, reward: -50, mean reward: -11.13, score: -55.65999834212661, epsilon: 0.8220657253137839, total steps: 2886
episode:113, reward: -3.9793895402706596, mean reward: -1.15, score: -40.260194308925065, epsilon: 0.8211655071969273, total steps: 2921
episode:114, reward: -50, mean reward: -2.44, score: -51.17253229091213, epsilon: 0.8206258802333615, total steps: 2942
episode:115, reward: -50, mean reward: -6.68, score: -60.12069105529059, epsilon: 0.8203947271439885, total steps: 2951
episode:116, reward: -50, mean reward: -12.24, score: -48.96949703498851, epsilon: 0.8202920146946847, total steps: 2955
episode:117, reward: -2.304300768087586, mean reward: -0.53, score: -18.583190405789395, epsilon: 0.8193938647002446, total steps: 2990
episode:118, reward: -50, mean reward: -2.96, score: -53.286060967505506, epsilon: 0.818932366844626, total steps: 3008
episode:119, reward: -50, mean reward: -2.36, score: -42.39987689790814, epsilon: 0.8184711458046678, total steps: 3026
episode:120, reward: -50, mean reward: -5.49, score: -71.42606826360623, epsilon: 0.8181382137819672, total steps: 3039
episode:121, reward: 0.3588954114141245, mean reward: 0.12, score: 4.210057952217085, epsilon: 0.8172425750900472, total steps: 3074
episode:122, reward: -50, mean reward: -0.94, score: -28.202239999115704, epsilon: 0.8164757160084029, total steps: 3104
episode:123, reward: -50, mean reward: -5.77, score: -63.44777767521384, epsilon: 0.8161947264304372, total steps: 3115
episode:124, reward: -50, mean reward: -3.19, score: -79.81865300181852, epsilon: 0.8155564967910295, total steps: 3140
episode:125, reward: -0.21195392892295217, mean reward: -0.12, score: -4.061598316825325, epsilon: 0.8146638683459468, total steps: 3175
episode:126, reward: -50, mean reward: -3.38, score: -64.29626801209434, epsilon: 0.8141797345545442, total steps: 3194
episode:127, reward: -50, mean reward: -3.25, score: -84.46097985711012, epsilon: 0.8135177323603175, total steps: 3220
episode:128, reward: -0.5992967311956647, mean reward: -0.63, score: -21.990067820773305, epsilon: 0.8126274810867844, total steps: 3255
episode:129, reward: 0.18824891195146165, mean reward: -0.45, score: -15.788232864836175, epsilon: 0.8117382678341071, total steps: 3290
episode:130, reward: -50, mean reward: -1.64, score: -44.349044464324805, epsilon: 0.8110530118045244, total steps: 3317
episode:131, reward: -50, mean reward: -6.13, score: -49.00735228046932, epsilon: 0.8108500913919673, total steps: 3325
episode:132, reward: -50, mean reward: -6.85, score: -54.77531999008002, epsilon: 0.810647225084306, total steps: 3333
episode:133, reward: -1.9366925824909629, mean reward: -0.31, score: -10.68252793493167, epsilon: 0.809760320783148, total steps: 3368
episode:134, reward: -50, mean reward: -3.31, score: -56.32680356088903, epsilon: 0.8093299118954065, total steps: 3385
episode:135, reward: 0.2221427697370757, mean reward: 0.26, score: 9.229292991958744, epsilon: 0.8084445435634792, total steps: 3420
episode:136, reward: -50, mean reward: -6.81, score: -54.505077096525156, epsilon: 0.8082423186497157, total steps: 3428
episode:137, reward: -50, mean reward: -4.41, score: -70.48442981237207, epsilon: 0.8078380305661746, total steps: 3444
episode:138, reward: -50, mean reward: -3.08, score: -83.22931051801041, epsilon: 0.8071562831710108, total steps: 3471
episode:139, reward: -50, mean reward: -5.34, score: -48.07680073302774, epsilon: 0.8069291703546854, total steps: 3480
episode:140, reward: -50, mean reward: -5.0, score: -54.96914969980219, epsilon: 0.8066516805351311, total steps: 3491
episode:141, reward: -50, mean reward: -5.78, score: -51.997899697188586, epsilon: 0.8064247190768916, total steps: 3500
episode:142, reward: -50, mean reward: -2.95, score: -79.74395266122286, epsilon: 0.8057442430898487, total steps: 3527
episode:143, reward: -50, mean reward: -7.28, score: -43.672616420816155, epsilon: 0.8055931093551079, total steps: 3533
episode:144, reward: -50, mean reward: -17.35, score: -52.05329816593223, epsilon: 0.8055175538220121, total steps: 3536
episode:145, reward: -50, mean reward: -2.6, score: -67.66424212155701, epsilon: 0.8048630555988964, total steps: 3562
episode:146, reward: -50, mean reward: -8.27, score: -49.6016479859411, epsilon: 0.8047120980840313, total steps: 3568
episode:147, reward: -50, mean reward: -4.23, score: -46.54972250576236, epsilon: 0.804435421041958, total steps: 3579
episode:148, reward: -50, mean reward: -1.91, score: -53.554828198371524, epsilon: 0.8037316098119843, total steps: 3607
episode:149, reward: -50, mean reward: -3.56, score: -78.42476495463589, epsilon: 0.8031790759186448, total steps: 3629
episode:150, reward: 2.2258743201867617, mean reward: -0.22, score: -7.829761781782906, epsilon: 0.8023008793776655, total steps: 3664
episode:151, reward: -50, mean reward: -4.68, score: -60.80759872931259, epsilon: 0.8019749529524274, total steps: 3677
episode:152, reward: -50, mean reward: -6.28, score: -56.551485115839625, epsilon: 0.801749394302031, total steps: 3686
episode:153, reward: -50, mean reward: -3.41, score: -68.10703724657517, epsilon: 0.8012483950574667, total steps: 3706
episode:154, reward: 0.5430287020025162, mean reward: -0.86, score: -30.100667403372967, epsilon: 0.8003724496640673, total steps: 3741
episode:155, reward: -50, mean reward: -17.35, score: -52.05394507955617, epsilon: 0.8002974161708382, total steps: 3744
episode:156, reward: -50, mean reward: -2.29, score: -43.43727925716004, epsilon: 0.7998223782518161, total steps: 3763
episode:157, reward: -50, mean reward: -5.38, score: -64.52986573047718, epsilon: 0.7995225092783085, total steps: 3775
episode:158, reward: 0.2963363687717617, mean reward: -0.19, score: -6.5053827395224175, epsilon: 0.7986485762442136, total steps: 3810
episode:159, reward: -0.934694939759936, mean reward: -0.36, score: -12.62605074542617, epsilon: 0.7977756622041299, total steps: 3845
episode:160, reward: -50, mean reward: -12.86, score: -51.44391061636358, epsilon: 0.797675965429102, total steps: 3849
episode:161, reward: -50, mean reward: -7.41, score: -51.8547608987372, epsilon: 0.7975015280556536, total steps: 3856
episode:162, reward: -50, mean reward: -1.82, score: -45.5718861050382, epsilon: 0.796878869592667, total steps: 3881
episode:163, reward: -50, mean reward: -3.77, score: -45.282275294189105, epsilon: 0.7965801777871735, total steps: 3893
episode:164, reward: -50, mean reward: -1.63, score: -42.45908737977692, epsilon: 0.7959334219344429, total steps: 3919
episode:165, reward: 0.22364898048758164, mean reward: -0.72, score: -25.037483081312104, epsilon: 0.7950636737272923, total steps: 3954
episode:166, reward: -2.656648511676565, mean reward: -0.99, score: -34.508936131873355, epsilon: 0.7941949396347014, total steps: 3989
episode:167, reward: -50, mean reward: -1.11, score: -38.90342664847893, epsilon: 0.7933272184742266, total steps: 4024
episode:168, reward: -50, mean reward: -4.19, score: -46.144436304065636, epsilon: 0.7930547151227868, total steps: 4035
episode:169, reward: -3.216394937673556, mean reward: -0.8, score: -28.098953798012474, epsilon: 0.7921883234485582, total steps: 4070
episode:170, reward: -50, mean reward: -2.54, score: -73.72419802511195, epsilon: 0.79147122139106, total steps: 4099
episode:171, reward: -0.8097922478037844, mean reward: -0.56, score: -19.643252334143227, epsilon: 0.7906066760489485, total steps: 4134
episode:172, reward: -50, mean reward: -2.64, score: -50.25052101990596, epsilon: 0.7901377736555489, total steps: 4153
episode:173, reward: 0.5557665480382639, mean reward: -0.15, score: -5.190067867715641, epsilon: 0.7892747830953297, total steps: 4188
episode:174, reward: 2.416103200078169, mean reward: -0.58, score: -20.260184414513105, epsilon: 0.7884127987703462, total steps: 4223
episode:175, reward: -50, mean reward: -1.44, score: -47.53713576826547, epsilon: 0.7876009912676825, total steps: 4256
episode:176, reward: -50, mean reward: -4.73, score: -66.16063064807102, epsilon: 0.7872568577758178, total steps: 4270
episode:177, reward: -50, mean reward: -12.8, score: -51.20701442253076, epsilon: 0.7871585634145506, total steps: 4274
episode:178, reward: -1.104027919995275, mean reward: -0.98, score: -34.29154736505464, epsilon: 0.7862990465728827, total steps: 4309
episode:179, reward: -50, mean reward: -17.35, score: -52.053868757295106, epsilon: 0.786225420349598, total steps: 4312
episode:180, reward: -50, mean reward: -6.3, score: -50.418921656873096, epsilon: 0.7860291197454152, total steps: 4320
episode:181, reward: -50, mean reward: -2.13, score: -66.16326709164844, epsilon: 0.7852689491441301, total steps: 4351
episode:182, reward: -50, mean reward: -4.91, score: -63.78670148531131, epsilon: 0.7849504016231152, total steps: 4364
episode:183, reward: -50, mean reward: -3.55, score: -63.954783353256204, epsilon: 0.7845095636467595, total steps: 4382
episode:184, reward: -50, mean reward: -9.95, score: -49.75886256233872, epsilon: 0.7843871555871066, total steps: 4387
episode:185, reward: -50, mean reward: -2.12, score: -57.23909032120358, epsilon: 0.7837265044846683, total steps: 4414
episode:186, reward: -50, mean reward: -10.44, score: -52.20143219669262, epsilon: 0.7836042269240006, total steps: 4419
episode:187, reward: 2.976283882252858, mean reward: -0.3, score: -10.460190931573777, epsilon: 0.7827488543902553, total steps: 4454
episode:188, reward: -50, mean reward: -8.97, score: -53.79302162606726, epsilon: 0.7826023192733774, total steps: 4460
episode:189, reward: -50, mean reward: -3.8, score: -45.6417440155023, epsilon: 0.78230933694604, total steps: 4472
episode:190, reward: 2.3999535249436974, mean reward: -0.06, score: -2.2455999789981433, epsilon: 0.7814554742363671, total steps: 4507
episode:191, reward: -1.0813457449852137, mean reward: -0.27, score: -9.288495751187725, epsilon: 0.7806026071189803, total steps: 4542
episode:192, reward: -50, mean reward: -2.33, score: -58.145435256326834, epsilon: 0.7799940252240563, total steps: 4567
episode:193, reward: -2.123154631054547, mean reward: -0.09, score: -3.1573596738087133, epsilon: 0.7791428621363067, total steps: 4602
episode:194, reward: -1.807343532169881, mean reward: -1.02, score: -35.57728608137347, epsilon: 0.778292691493121, total steps: 4637
episode:195, reward: -1.7369092609278027, mean reward: -1.05, score: -36.58248054461407, epsilon: 0.7774435121373221, total steps: 4672
episode:196, reward: -1.487623460596069, mean reward: -0.34, score: -11.856444493790406, epsilon: 0.7765953229130826, total steps: 4707
episode:197, reward: -50, mean reward: -3.91, score: -62.5343854680188, epsilon: 0.7762079087271617, total steps: 4723
episode:198, reward: -50, mean reward: -1.87, score: -31.73975524661435, epsilon: 0.7757965074869099, total steps: 4740
episode:199, reward: -50, mean reward: -3.42, score: -71.71601146746218, epsilon: 0.7752886277103294, total steps: 4761
episode:200, reward: -50, mean reward: -1.07, score: -36.39522155494447, epsilon: 0.7744670995528141, total steps: 4795
episode:201, reward: -2.025806641165076, mean reward: 0.21, score: 7.175331638306915, epsilon: 0.7736223807850967, total steps: 4830
episode:202, reward: -50, mean reward: -4.48, score: -53.80499549839723, epsilon: 0.7733329897148552, total steps: 4842
episode:203, reward: -50, mean reward: -3.7, score: -48.16024845881208, epsilon: 0.7730196133224343, total steps: 4855
episode:204, reward: -50, mean reward: -2.12, score: -44.563735397208205, epsilon: 0.7725136766915884, total steps: 4876
episode:205, reward: -1.043127112888243, mean reward: -0.24, score: -8.553386688887628, epsilon: 0.7716712355883131, total steps: 4911
episode:206, reward: -50, mean reward: -3.17, score: -66.62768067064786, epsilon: 0.7711662424916058, total steps: 4932
episode:207, reward: -50, mean reward: -2.26, score: -74.52007266187354, epsilon: 0.7703733957705069, total steps: 4965
episode:208, reward: -50, mean reward: -3.13, score: -59.417523678343656, epsilon: 0.7699173037309102, total steps: 4984
episode:209, reward: -50, mean reward: -1.97, score: -64.95628822060715, epsilon: 0.7691258300871172, total steps: 5017
episode:210, reward: -50, mean reward: -5.15, score: -56.656764334334724, epsilon: 0.7688621989514137, total steps: 5028
episode:211, reward: -50, mean reward: -3.23, score: -74.29022017725342, epsilon: 0.768311282477184, total steps: 5051
episode:212, reward: -50, mean reward: -2.13, score: -68.30835979678005, epsilon: 0.7675454922699273, total steps: 5083
episode:213, reward: -50, mean reward: -8.48, score: -67.80056373568397, epsilon: 0.767354172315783, total steps: 5091
episode:214, reward: -1.945158785989662, mean reward: -0.44, score: -15.358692511348721, epsilon: 0.7665177471243152, total steps: 5126
episode:215, reward: -50, mean reward: -3.3, score: -56.095412806717064, epsilon: 0.7661118354201227, total steps: 5143
episode:216, reward: -50, mean reward: -6.19, score: -49.5131370028171, epsilon: 0.7659208977235018, total steps: 5151
episode:217, reward: 0.9265457343371963, mean reward: -0.2, score: -6.924386846530098, epsilon: 0.7650861437106813, total steps: 5186
episode:218, reward: -0.3324074517132658, mean reward: -0.16, score: -5.653353893312186, epsilon: 0.7642523630096667, total steps: 5221
episode:219, reward: -50, mean reward: -2.57, score: -69.36224802578454, epsilon: 0.7636098250684029, total steps: 5248
episode:220, reward: -50, mean reward: -4.67, score: -56.003577214068514, epsilon: 0.7633244382195505, total steps: 5260
episode:221, reward: -50, mean reward: -2.05, score: -53.39282915740074, epsilon: 0.762706491522008, total steps: 5286
episode:222, reward: -50, mean reward: -1.92, score: -51.80815100070737, epsilon: 0.7620653442391929, total steps: 5313
episode:223, reward: -50, mean reward: -14.05, score: -56.182741344536936, epsilon: 0.7619704085224828, total steps: 5317
episode:224, reward: -50, mean reward: -5.39, score: -53.87597305566928, epsilon: 0.7617331246024923, total steps: 5327
episode:225, reward: -50, mean reward: -4.93, score: -69.00810711790339, epsilon: 0.7614010599654529, total steps: 5341
episode:226, reward: -2.528777036936674, mean reward: 0.59, score: 20.80850632761559, epsilon: 0.7605715760218785, total steps: 5376
episode:227, reward: -50, mean reward: -2.55, score: -45.98535544207701, epsilon: 0.7601453609535724, total steps: 5394
episode:228, reward: 0.6112606433007386, mean reward: -0.18, score: -6.328645491619682, epsilon: 0.759317341137938, total steps: 5429
episode:229, reward: -0.605059415821529, mean reward: -1.01, score: -35.51929291964018, epsilon: 0.7584902867821273, total steps: 5464
episode:230, reward: -0.5921930373492614, mean reward: -0.16, score: -5.700798480029164, epsilon: 0.7576641967604275, total steps: 5499
episode:231, reward: -50, mean reward: -4.76, score: -57.0626154317886, epsilon: 0.7573811876873114, total steps: 5511
episode:232, reward: -50, mean reward: -13.68, score: -54.7096034508144, epsilon: 0.7572868764831732, total steps: 5515
episode:233, reward: -50, mean reward: -17.33, score: -51.99311080564857, epsilon: 0.7572161513318413, total steps: 5518
episode:234, reward: 1.3461799512857056, mean reward: -0.06, score: -2.1162231383892447, epsilon: 0.7563915469347172, total steps: 5553
episode:235, reward: -50, mean reward: -7.09, score: -56.72780592400605, epsilon: 0.7562032009694463, total steps: 5561
episode:236, reward: 1.7773509925734459, mean reward: 0.18, score: 6.216523396522234, epsilon: 0.7553797776586441, total steps: 5596
episode:237, reward: -50, mean reward: -5.41, score: -81.20391605288299, epsilon: 0.7550271759275934, total steps: 5611
episode:238, reward: -50, mean reward: -2.55, score: -45.81301921540174, epsilon: 0.7546042865015513, total steps: 5629
episode:239, reward: -3.086805315003801, mean reward: -0.48, score: -16.822812992642554, epsilon: 0.7537827275032346, total steps: 5664
episode:240, reward: -2.3142944584546115, mean reward: -0.52, score: -18.248313229021136, epsilon: 0.7529621264315167, total steps: 5699
episode:241, reward: -50, mean reward: -1.82, score: -56.4220107302491, epsilon: 0.7522361074086349, total steps: 5730
episode:242, reward: -50, mean reward: -2.47, score: -54.3304648405869, epsilon: 0.7517213230405402, total steps: 5752
episode:243, reward: -50, mean reward: -3.24, score: -51.85812182259508, epsilon: 0.7513471714508779, total steps: 5768
episode:244, reward: 1.1759980085371637, mean reward: -0.64, score: -22.43660401706245, epsilon: 0.7505294102043344, total steps: 5803
episode:245, reward: -50, mean reward: -2.79, score: -75.32313510755617, epsilon: 0.7498992173644664, total steps: 5830
episode:246, reward: 0.3560351003353901, mean reward: -1.04, score: -36.35073616822777, epsilon: 0.7490831444126602, total steps: 5865
episode:247, reward: -50, mean reward: -7.29, score: -51.053761219994215, epsilon: 0.748920044041414, total steps: 5872
episode:248, reward: -50, mean reward: -3.06, score: -49.0086723113904, epsilon: 0.7485473860688845, total steps: 5888
episode:249, reward: -50, mean reward: -2.75, score: -85.18788580095867, epsilon: 0.7478259265882082, total steps: 5919
episode:250, reward: 0.27257463139753213, mean reward: 0.08, score: 2.9127384426501806, epsilon: 0.7470122710652001, total steps: 5954
episode:251, reward: -50, mean reward: -2.39, score: -78.8500820302007, epsilon: 0.7462459791048743, total steps: 5987
episode:252, reward: -50, mean reward: -1.75, score: -57.65736690390946, epsilon: 0.7454805296022683, total steps: 6020
episode:253, reward: -0.002753836266407461, mean reward: 0.01, score: 0.3793009901131086, epsilon: 0.7446696087801912, total steps: 6055
episode:254, reward: -50, mean reward: -2.91, score: -61.0910340258219, epsilon: 0.7441835102083942, total steps: 6076
episode:255, reward: 0.04662238805772745, mean reward: -0.2, score: -6.999651836297858, epsilon: 0.7433741016932596, total steps: 6111
episode:256, reward: 1.2118169099642557, mean reward: -1.08, score: -37.64392355908191, epsilon: 0.7425656369374258, total steps: 6146
episode:257, reward: -1.16975176521521, mean reward: -0.33, score: -11.611243054887012, epsilon: 0.7417581148404826, total steps: 6181
episode:258, reward: -2.311798704800566, mean reward: -0.82, score: -28.85350652196564, epsilon: 0.7409515343033026, total steps: 6216
episode:259, reward: -50, mean reward: -3.31, score: -49.69748669078592, epsilon: 0.7406061448906996, total steps: 6231
episode:260, reward: -50, mean reward: -3.02, score: -75.59517876998709, epsilon: 0.7400308794971622, total steps: 6256
episode:261, reward: -0.016604016592850712, mean reward: -1.13, score: -39.430244863810174, epsilon: 0.73922631289286, total steps: 6291
episode:262, reward: -50, mean reward: -1.6, score: -52.76972908129221, epsilon: 0.7384685807777459, total steps: 6324
episode:263, reward: -50, mean reward: -13.26, score: -53.059573606863836, epsilon: 0.7383767910864243, total steps: 6328
episode:264, reward: -50, mean reward: -2.85, score: -57.037060274747034, epsilon: 0.737918026164332, total steps: 6348
episode:265, reward: -50, mean reward: -10.95, score: -54.75223975256816, epsilon: 0.7378033827138575, total steps: 6353
episode:266, reward: -50, mean reward: -4.37, score: -61.14079543044278, epsilon: 0.7374824826844216, total steps: 6367
episode:267, reward: -0.10158925225994153, mean reward: -0.9, score: -31.425738041107678, epsilon: 0.736680887476083, total steps: 6402
episode:268, reward: 0.2478580434495825, mean reward: -1.21, score: -42.17903940137725, epsilon: 0.7358802269168362, total steps: 6437
episode:269, reward: -50, mean reward: -2.04, score: -65.166654308609, epsilon: 0.7351490113924013, total steps: 6469
episode:270, reward: -50, mean reward: -4.84, score: -67.73681884293248, epsilon: 0.7348293497805956, total steps: 6483
episode:271, reward: -50, mean reward: -2.99, score: -47.79685731886141, epsilon: 0.7344642048413517, total steps: 6499
episode:272, reward: -50, mean reward: -3.75, score: -44.96334969483206, epsilon: 0.7341904739092513, total steps: 6511
episode:273, reward: -50, mean reward: -9.89, score: -49.4261543995363, epsilon: 0.7340764516657173, total steps: 6516
episode:274, reward: -50, mean reward: -7.21, score: -57.665689188670086, epsilon: 0.7338940555991629, total steps: 6524
episode:275, reward: -50, mean reward: -6.97, score: -48.79530207279808, epsilon: 0.733734498935191, total steps: 6531
episode:276, reward: -50, mean reward: -1.46, score: -42.23148441968314, epsilon: 0.7330738749392615, total steps: 6560
episode:277, reward: -50, mean reward: -2.62, score: -70.78101816590049, epsilon: 0.7324593850137607, total steps: 6587
episode:278, reward: 1.924773876825327, mean reward: -0.56, score: -19.74859962632854, epsilon: 0.7316636466688698, total steps: 6622
episode:279, reward: -50, mean reward: -3.22, score: -67.539214239713, epsilon: 0.7311866490848334, total steps: 6643
episode:280, reward: -2.9610446848880656, mean reward: -0.19, score: -6.805246622848671, epsilon: 0.7303923947326956, total steps: 6678
episode:281, reward: -0.5307189561935388, mean reward: -1.2, score: -42.11904582556315, epsilon: 0.7295990664703111, total steps: 6713
episode:282, reward: -50, mean reward: -2.33, score: -62.957048675768505, epsilon: 0.7289877024655571, total steps: 6740
episode:283, reward: 0.21891437885102505, mean reward: 0.02, score: 0.6128640406115835, epsilon: 0.7281960120552182, total steps: 6775
episode:284, reward: -50, mean reward: -1.91, score: -45.849456866033904, epsilon: 0.7276536722104368, total steps: 6799
episode:285, reward: -50, mean reward: -4.73, score: -51.982388170422496, epsilon: 0.7274052447451115, total steps: 6810
episode:286, reward: -2.435024029540216, mean reward: -0.49, score: -17.284819882156427, epsilon: 0.7266153994589147, total steps: 6845
episode:287, reward: -50, mean reward: -2.84, score: -53.98390334788297, epsilon: 0.726187012042925, total steps: 6864
episode:288, reward: -2.214311327623818, mean reward: -0.61, score: -21.289774174140604, epsilon: 0.7253985871994615, total steps: 6899
episode:289, reward: -50, mean reward: -2.59, score: -67.39057487761119, epsilon: 0.7248134953336529, total steps: 6925
episode:290, reward: -1.2560564143567206, mean reward: -0.81, score: -28.339986727184908, epsilon: 0.7240266719919591, total steps: 6960
episode:291, reward: -2.2432270544257165, mean reward: -0.99, score: -34.606164258288544, epsilon: 0.7232407660755618, total steps: 6995
episode:292, reward: -50, mean reward: -4.18, score: -75.16919243723919, epsilon: 0.7228369427750213, total steps: 7013
episode:293, reward: -50, mean reward: -3.1, score: -55.8051197741037, epsilon: 0.7224333616957875, total steps: 7031
episode:294, reward: 1.5799671379994038, mean reward: -0.31, score: -10.92239728016773, epsilon: 0.7216493135574878, total steps: 7066
episode:295, reward: -0.9171530532249221, mean reward: -1.05, score: -36.80891701910798, epsilon: 0.7208661796086353, total steps: 7101
episode:296, reward: 0.1413613566989227, mean reward: -0.93, score: -32.58084847362869, epsilon: 0.7200839587832975, total steps: 7136
episode:297, reward: -50, mean reward: -2.06, score: -47.41934597685082, epsilon: 0.7195704246281434, total steps: 7159
episode:298, reward: -50, mean reward: -7.02, score: -56.121250403206034, epsilon: 0.7193918963197417, total steps: 7167
episode:299, reward: -50, mean reward: -1.4, score: -29.502721048107105, epsilon: 0.7189234859550722, total steps: 7188
episode:300, reward: -50, mean reward: -2.51, score: -42.61910997842912, epsilon: 0.7185445366921293, total steps: 7205
episode:301, reward: -50, mean reward: -2.5, score: -40.05650688639375, epsilon: 0.7181880746708819, total steps: 7221
episode:302, reward: -50, mean reward: -3.45, score: -65.5128334080695, epsilon: 0.7177650228708012, total steps: 7240
episode:303, reward: -50, mean reward: -2.39, score: -69.18312632408433, epsilon: 0.7171198285761768, total steps: 7269
episode:304, reward: -50, mean reward: -17.35, score: -52.05297438687586, epsilon: 0.717053119928807, total steps: 7272
episode:305, reward: -0.35683507630776035, mean reward: -0.71, score: -24.9239507141896, epsilon: 0.7162753450791056, total steps: 7307
episode:306, reward: 1.107486425559415, mean reward: -0.08, score: -2.65601712488305, epsilon: 0.7154984771042823, total steps: 7342
episode:307, reward: -50, mean reward: -2.43, score: -60.86689697221212, epsilon: 0.7149441260517144, total steps: 7367
episode:308, reward: 0.24488458104093525, mean reward: -0.25, score: -8.710990341423553, epsilon: 0.7141688102601401, total steps: 7402
episode:309, reward: -50, mean reward: -1.74, score: -55.78291932204925, epsilon: 0.7134607412331458, total steps: 7434
episode:310, reward: 0.9172927259392338, mean reward: -0.7, score: -24.50279625121067, epsilon: 0.7126871550480598, total steps: 7469
episode:311, reward: -50, mean reward: -3.64, score: -54.6073054356641, epsilon: 0.712355894292626, total steps: 7484
episode:312, reward: 1.3844049493282569, mean reward: -0.45, score: -15.759059813685639, epsilon: 0.7115835963440198, total steps: 7519
episode:313, reward: 0.02654332281682059, mean reward: 0.48, score: 16.755431595188753, epsilon: 0.7108121988842997, total steps: 7554
episode:314, reward: -50, mean reward: -2.91, score: -52.44525032501241, epsilon: 0.7104158304873793, total steps: 7572
episode:315, reward: -50, mean reward: -3.04, score: -54.65919857326338, epsilon: 0.710019699840165, total steps: 7590
episode:316, reward: -50, mean reward: -1.59, score: -47.79078724194301, epsilon: 0.7093600100401989, total steps: 7620
episode:317, reward: 0.8721479220373283, mean reward: -0.64, score: -22.25919984978316, epsilon: 0.7085912052518143, total steps: 7655
episode:318, reward: 0.24631960007479847, mean reward: -0.5, score: -17.569157768526566, epsilon: 0.7078232968793385, total steps: 7690
episode:319, reward: 1.4945475379932418, mean reward: -0.58, score: -20.414208810438964, epsilon: 0.7070562838775628, total steps: 7725
episode:320, reward: -50, mean reward: -2.14, score: -62.18881285113528, epsilon: 0.7064214363622161, total steps: 7754
episode:321, reward: -50, mean reward: -2.61, score: -78.37357426069144, epsilon: 0.7057653430271958, total steps: 7784
episode:322, reward: -2.769415906481754, mean reward: -0.65, score: -22.580250955326136, epsilon: 0.7050007295715736, total steps: 7819
episode:323, reward: -50, mean reward: -2.96, score: -50.276653978005356, epsilon: 0.7046296676356275, total steps: 7836
episode:324, reward: -50, mean reward: -5.68, score: -68.16441345356267, epsilon: 0.7043678681319646, total steps: 7848
episode:325, reward: -50, mean reward: -0.98, score: -30.39639073656153, epsilon: 0.7036920372409917, total steps: 7879
episode:326, reward: 0.7691825325626951, mean reward: -0.72, score: -25.166654559860433, epsilon: 0.7029298412316688, total steps: 7914
episode:327, reward: -50, mean reward: -6.94, score: -55.52909482080747, epsilon: 0.7027557498205601, total steps: 7922
episode:328, reward: -50, mean reward: -3.13, score: -81.50074939639237, epsilon: 0.7021902732459593, total steps: 7948
episode:329, reward: -50, mean reward: -2.38, score: -59.533372229109915, epsilon: 0.7016470077436526, total steps: 7973
episode:330, reward: -50, mean reward: -8.49, score: -59.42055637815602, epsilon: 0.7014949745130791, total steps: 7980
episode:331, reward: -3.092277409035404, mean reward: -0.16, score: -5.739039334359404, epsilon: 0.7007353402489634, total steps: 8015
episode:332, reward: -50, mean reward: -5.44, score: -54.437290153511185, epsilon: 0.7005184646168272, total steps: 8025
episode:333, reward: -50, mean reward: -5.12, score: -61.408189278158346, epsilon: 0.7002583092655196, total steps: 8037
episode:334, reward: -50, mean reward: -1.89, score: -58.510572249730956, epsilon: 0.6995867227254163, total steps: 8068
episode:335, reward: -50, mean reward: -3.62, score: -57.979523037635204, epsilon: 0.6992403688425414, total steps: 8084
episode:336, reward: -50, mean reward: -1.88, score: -52.6268222595825, epsilon: 0.698634693857249, total steps: 8112
episode:337, reward: 0.9858101203424781, mean reward: -1.03, score: -36.06468966485522, epsilon: 0.6978783946414088, total steps: 8147
episode:338, reward: -50, mean reward: -12.74, score: -50.97767494241057, epsilon: 0.6977920166141197, total steps: 8151
episode:339, reward: -3.056441546399128, mean reward: 0.13, score: 4.431441349971493, epsilon: 0.697036699948464, total steps: 8186
episode:340, reward: 1.6646052250621324, mean reward: -0.87, score: -30.29709452703446, epsilon: 0.6962822639717497, total steps: 8221
episode:341, reward: -0.960286471346933, mean reward: -0.53, score: -18.53447736567466, epsilon: 0.6955287076571057, total steps: 8256
episode:342, reward: -1.7198452354773792, mean reward: -0.3, score: -10.501964757007954, epsilon: 0.694776029978858, total steps: 8291
episode:343, reward: 0.8939515539765353, mean reward: -0.5, score: -17.47912009112457, epsilon: 0.6940242299125282, total steps: 8326
episode:344, reward: -50, mean reward: -1.97, score: -39.489715782127234, epsilon: 0.6935950235106171, total steps: 8346
episode:345, reward: -0.059607775722327005, mean reward: -0.84, score: -29.555279904564514, epsilon: 0.692844600481739, total steps: 8381
episode:346, reward: -50, mean reward: -3.08, score: -64.71069693209841, epsilon: 0.692394766721586, total steps: 8402
episode:347, reward: -0.3505448038207817, mean reward: -0.88, score: -30.67124161747489, epsilon: 0.6916457431757712, total steps: 8437
episode:348, reward: -50, mean reward: -3.38, score: -50.63527203717905, epsilon: 0.6913250004965352, total steps: 8452
episode:349, reward: -0.7744810628190919, mean reward: -1.04, score: -36.391548595356625, epsilon: 0.6905772242835642, total steps: 8487
episode:350, reward: 1.4266402269375646, mean reward: -0.82, score: -28.742076331509907, epsilon: 0.6898303199674692, total steps: 8522
episode:351, reward: -50, mean reward: -3.45, score: -75.87486783714425, epsilon: 0.6893612830673764, total steps: 8544
episode:352, reward: 0.13119305182124208, mean reward: 0.17, score: 6.060229758188939, epsilon: 0.6886157965221733, total steps: 8579
episode:353, reward: -50, mean reward: -3.2, score: -57.58742182215053, epsilon: 0.6882327419721166, total steps: 8597
episode:354, reward: 1.189123269981195, mean reward: 0.7, score: 24.4494507236318, epsilon: 0.687488571290455, total steps: 8632
episode:355, reward: -50, mean reward: -1.95, score: -50.67334857814359, epsilon: 0.6869363205385627, total steps: 8658
episode:356, reward: -50, mean reward: -2.51, score: -45.11025142391151, epsilon: 0.6865542733718509, total steps: 8676
episode:357, reward: -1.8931374379917543, mean reward: -1.02, score: -35.76693020040045, epsilon: 0.6858120597617092, total steps: 8711
episode:358, reward: -1.1397287008007595, mean reward: -0.58, score: -20.196234154969574, epsilon: 0.6850707115625249, total steps: 8746
episode:359, reward: 0.6058826790703336, mean reward: -0.61, score: -21.47414442221725, epsilon: 0.6843302277652404, total steps: 8781
episode:360, reward: -2.038475336100646, mean reward: -0.92, score: -32.131178428863365, epsilon: 0.683590607361975, total steps: 8816
episode:361, reward: -50, mean reward: -2.37, score: -35.575972099672384, epsilon: 0.6832738912439218, total steps: 8831
episode:362, reward: -50, mean reward: -2.8, score: -67.1160746675616, epsilon: 0.6827674747245434, total steps: 8855
episode:363, reward: -0.6572514280865107, mean reward: -0.47, score: -16.582616616770594, epsilon: 0.6820296764700319, total steps: 8890
episode:364, reward: -1.3951055211182393, mean reward: -1.03, score: -35.90942833537429, epsilon: 0.6812927384782334, total steps: 8925
episode:365, reward: -50, mean reward: -2.23, score: -40.1927182188235, epsilon: 0.6809140764451161, total steps: 8943
episode:366, reward: -50, mean reward: -2.48, score: -54.53049570774124, epsilon: 0.6804515757267133, total steps: 8965
episode:367, reward: -50, mean reward: -3.14, score: -72.30102884063643, epsilon: 0.6799684147540284, total steps: 8988
episode:368, reward: -50, mean reward: -2.41, score: -70.02743264800512, epsilon: 0.679359739526857, total steps: 9017
episode:369, reward: -50, mean reward: -4.24, score: -46.628019469270924, epsilon: 0.6791290165908204, total steps: 9028
episode:370, reward: -50, mean reward: -12.74, score: -50.94553486481777, epsilon: 0.6790451383139511, total steps: 9032
episode:371, reward: -2.828476169231152, mean reward: -0.66, score: -22.952623519798493, epsilon: 0.67831168025298, total steps: 9067
episode:372, reward: -50, mean reward: -8.4, score: -58.81461353684338, epsilon: 0.6781650912969643, total steps: 9074
episode:373, reward: -50, mean reward: -6.71, score: -46.95476906584105, epsilon: 0.6780185365410483, total steps: 9081
episode:374, reward: -50, mean reward: -17.35, score: -52.053411286931464, epsilon: 0.677955737827382, total steps: 9084
episode:375, reward: -50, mean reward: -3.19, score: -50.986905869064, epsilon: 0.6776209173939263, total steps: 9100
episode:376, reward: -50, mean reward: -3.62, score: -54.365241646085764, epsilon: 0.6773071853747701, total steps: 9115
episode:377, reward: -50, mean reward: -9.53, score: -47.641189509857156, epsilon: 0.6772026428893234, total steps: 9120
episode:378, reward: -50, mean reward: -5.81, score: -58.13787549766832, epsilon: 0.6769936101824136, total steps: 9130
episode:379, reward: -3.165700316231238, mean reward: -0.6, score: -20.85546466474929, epsilon: 0.6762625441752935, total steps: 9165
episode:380, reward: -50, mean reward: -1.96, score: -45.02582734567628, epsilon: 0.6757825935626693, total steps: 9188
episode:381, reward: -50, mean reward: -6.04, score: -48.338771082165266, epsilon: 0.6756157404524561, total steps: 9196
episode:382, reward: -50, mean reward: -2.08, score: -58.17825442842724, epsilon: 0.6750321048336901, total steps: 9224
episode:383, reward: -0.08796001411678844, mean reward: -0.34, score: -11.870705289135287, epsilon: 0.6743033259150825, total steps: 9259
episode:384, reward: 0.22155770399373864, mean reward: -0.83, score: -28.960100182862277, epsilon: 0.6735753967427647, total steps: 9294
episode:385, reward: 2.679100303848827, mean reward: 0.21, score: 7.332063199776542, epsilon: 0.6728483163259444, total steps: 9329
episode:386, reward: -50, mean reward: -2.73, score: -46.444431759772385, epsilon: 0.672495468929564, total steps: 9346
episode:387, reward: -50, mean reward: -2.49, score: -62.31490090792033, epsilon: 0.6719769387896884, total steps: 9371
episode:388, reward: -0.8608949279616809, mean reward: -0.94, score: -32.75566537125334, epsilon: 0.6712517221530635, total steps: 9406
episode:389, reward: -1.3862102398312857, mean reward: -1.12, score: -39.34963291340614, epsilon: 0.6705273511091564, total steps: 9441
episode:390, reward: -50, mean reward: -1.88, score: -65.81980591843262, epsilon: 0.6698038246720173, total steps: 9476
episode:391, reward: 1.5630584810510584, mean reward: 0.31, score: 10.817101396120961, epsilon: 0.6690811418568464, total steps: 9511
episode:392, reward: -2.5634252570388867, mean reward: -0.37, score: -12.827353026699825, epsilon: 0.668359301679992, total steps: 9546
episode:393, reward: 1.354623840205221, mean reward: -0.26, score: -8.954992078462709, epsilon: 0.6676383031589492, total steps: 9581
episode:394, reward: -50, mean reward: -4.24, score: -63.65779912005536, epsilon: 0.6673295611992919, total steps: 9596
episode:395, reward: -50, mean reward: -2.73, score: -49.17241592739654, epsilon: 0.6669592745596727, total steps: 9614
episode:396, reward: -50, mean reward: -4.88, score: -58.57360165677872, epsilon: 0.6667125402000106, total steps: 9626
episode:397, reward: -2.753682511330595, mean reward: 0.09, score: 3.2565116430640444, epsilon: 0.6659934617804175, total steps: 9661
episode:398, reward: -50, mean reward: -3.79, score: -56.91106063213584, epsilon: 0.6656855420358784, total steps: 9676
episode:399, reward: -50, mean reward: -3.05, score: -54.9610437648893, epsilon: 0.6653162415118931, total steps: 9694
episode:400, reward: -50, mean reward: -3.34, score: -76.85268589073436, epsilon: 0.6648446798484694, total steps: 9717
episode:401, reward: -50, mean reward: -3.04, score: -72.84496412989984, epsilon: 0.664353000802432, total steps: 9741
episode:402, reward: -50, mean reward: -2.8, score: -47.563643664915816, epsilon: 0.6640049660544689, total steps: 9758
episode:403, reward: -50, mean reward: -2.63, score: -52.63749748383594, epsilon: 0.6635957658256645, total steps: 9778
episode:404, reward: -50, mean reward: -1.54, score: -52.44155194908831, epsilon: 0.6629007512070716, total steps: 9812
episode:405, reward: -50, mean reward: -1.91, score: -61.08102975907241, epsilon: 0.662247338954272, total steps: 9844
episode:406, reward: -50, mean reward: -4.8, score: -43.1887483573347, epsilon: 0.6620636923009611, total steps: 9853
episode:407, reward: -50, mean reward: -5.41, score: -43.24741777641162, epsilon: 0.6619004970766778, total steps: 9861
episode:408, reward: -50, mean reward: -4.25, score: -42.53189468184067, epsilon: 0.6616965642350141, total steps: 9871
episode:409, reward: -50, mean reward: -1.39, score: -47.38687839216223, epsilon: 0.6610037008256417, total steps: 9905
episode:410, reward: -1.9832385595078676, mean reward: -0.98, score: -34.21862680693843, epsilon: 0.6602912788349802, total steps: 9940
episode:411, reward: -50, mean reward: -2.12, score: -65.69943968551746, epsilon: 0.6596609702290497, total steps: 9971
episode:412, reward: -50, mean reward: -2.23, score: -49.11581299338479, epsilon: 0.6592140494085444, total steps: 9993
episode:413, reward: -50, mean reward: -6.96, score: -62.654997094487214, epsilon: 0.6590313126056129, total steps: 10002
episode:414, reward: 0.8808966550975299, mean reward: 0.48, score: 16.95309883355779, epsilon: 0.6583211903927434, total steps: 10037
episode:415, reward: -50, mean reward: -6.8, score: -47.61877245275346, epsilon: 0.6581792653402185, total steps: 10044
episode:416, reward: 0.8639468547346496, mean reward: -0.19, score: -6.517179045286241, epsilon: 0.657470136602852, total steps: 10079
episode:417, reward: -2.949475204472975, mean reward: -0.69, score: -24.26961700105477, epsilon: 0.6567618346999318, total steps: 10114
episode:418, reward: -50, mean reward: -1.83, score: -45.846245215229345, epsilon: 0.6562564104603641, total steps: 10139
episode:419, reward: -50, mean reward: -2.1, score: -56.80274017502026, epsilon: 0.6557110251511524, total steps: 10166
episode:420, reward: -50, mean reward: -3.21, score: -41.676923765199035, epsilon: 0.6554486072349085, total steps: 10179
episode:421, reward: -50, mean reward: -2.18, score: -65.38438572531055, epsilon: 0.6548434612510944, total steps: 10209
episode:422, reward: -50, mean reward: -2.29, score: -50.33666657921512, epsilon: 0.6544000719754482, total steps: 10231
episode:423, reward: -50, mean reward: -1.31, score: -36.78059376351658, epsilon: 0.6538362284095328, total steps: 10259
episode:424, reward: -50, mean reward: -8.04, score: -48.23954036959617, epsilon: 0.6537154732397704, total steps: 10265
episode:425, reward: -0.27304918112281484, mean reward: -0.09, score: -3.090001125312, epsilon: 0.653011549223177, total steps: 10300
episode:426, reward: -50, mean reward: -3.66, score: -47.560036142570624, epsilon: 0.6527503008264209, total steps: 10313
episode:427, reward: -0.15661024255044254, mean reward: 0.23, score: 8.073473270614585, epsilon: 0.6520475021877116, total steps: 10348
episode:428, reward: -50, mean reward: -2.73, score: -35.4325398129678, epsilon: 0.6517866714541707, total steps: 10361
episode:429, reward: 0.9636891927964655, mean reward: 0.53, score: 18.70068165029116, epsilon: 0.6510849963941806, total steps: 10396
episode:430, reward: -50, mean reward: -3.97, score: -47.64446157406246, epsilon: 0.6508446104760117, total steps: 10408
episode:431, reward: -50, mean reward: -1.95, score: -42.83295495223439, epsilon: 0.6504041526159504, total steps: 10430
episode:432, reward: -3.0671727202672514, mean reward: -0.15, score: -5.382797195689932, epsilon: 0.6497040895540899, total steps: 10465
episode:433, reward: -0.8154593414811018, mean reward: -0.42, score: -14.818393033922035, epsilon: 0.6490048427562215, total steps: 10500
episode:434, reward: -0.16502118086285122, mean reward: 0.41, score: 14.206903406792577, epsilon: 0.6483064112705927, total steps: 10535
episode:435, reward: -50, mean reward: -4.24, score: -55.129455169612896, epsilon: 0.6480472013252532, total steps: 10548
episode:436, reward: -2.7291044464150787, mean reward: 0.36, score: 12.60742182250317, epsilon: 0.6473498864364858, total steps: 10583
episode:437, reward: -50, mean reward: -2.27, score: -74.84562683896971, epsilon: 0.6466931628256113, total steps: 10616
episode:438, reward: -50, mean reward: -3.08, score: -43.15805356526434, epsilon: 0.6464147709794423, total steps: 10630
episode:439, reward: 0.3307427661855513, mean reward: -1.17, score: -40.9069350076077, epsilon: 0.6457193594822174, total steps: 10665
episode:440, reward: -0.845913587105656, mean reward: -0.62, score: -21.690554634436097, epsilon: 0.6450247588253237, total steps: 10700
episode:441, reward: 1.2867420049639406, mean reward: 0.35, score: 12.13010210867111, epsilon: 0.6443309680633326, total steps: 10735
episode:442, reward: -50, mean reward: -1.34, score: -47.063586797023675, epsilon: 0.6436379862519175, total steps: 10770
episode:443, reward: -50, mean reward: -8.0, score: -56.01269948274762, epsilon: 0.6434994868806803, total steps: 10777
episode:444, reward: -0.6847456953357494, mean reward: -0.47, score: -16.370248277202677, epsilon: 0.6428074745649959, total steps: 10812
episode:445, reward: -50, mean reward: -3.46, score: -55.36311267176424, epsilon: 0.642491394873971, total steps: 10828
episode:446, reward: -50, mean reward: -2.57, score: -61.67176247757203, epsilon: 0.6420175913047691, total steps: 10852
episode:447, reward: -50, mean reward: -4.27, score: -55.51802640082221, epsilon: 0.641761105924383, total steps: 10865
episode:448, reward: 1.8499931886751426, mean reward: 0.1, score: 3.653880047455459, epsilon: 0.6410711205372093, total steps: 10900
episode:449, reward: -2.2609327599232074, mean reward: -1.06, score: -37.250105927183824, epsilon: 0.6403819396635965, total steps: 10935
episode:450, reward: -50, mean reward: -1.73, score: -31.212534182925936, epsilon: 0.6400278167472968, total steps: 10953
episode:451, reward: -1.2344421107955839, mean reward: -0.14, score: -5.038841258014344, epsilon: 0.6393398523516888, total steps: 10988
episode:452, reward: -50, mean reward: -2.43, score: -65.73087054972189, epsilon: 0.6388096850956237, total steps: 11015
episode:453, reward: -50, mean reward: -6.55, score: -58.9284596553527, epsilon: 0.6386330686838815, total steps: 11024
episode:454, reward: 0.023039526301886326, mean reward: -0.73, score: -25.552944707113227, epsilon: 0.6379467305455129, total steps: 11059
episode:455, reward: -50, mean reward: -5.57, score: -50.11962958907935, epsilon: 0.6377703729813065, total steps: 11068
episode:456, reward: 1.5657966881477137, mean reward: 0.0, score: 0.11474895949370989, epsilon: 0.6370850407343734, total steps: 11103
episode:457, reward: 1.870155108395977, mean reward: 0.49, score: 17.01014103438922, epsilon: 0.6364005075755031, total steps: 11138
episode:458, reward: 1.3584644437995053, mean reward: -0.14, score: -4.741532751198122, epsilon: 0.6357167725729699, total steps: 11173
episode:459, reward: -50, mean reward: -2.6, score: -67.57919874583837, epsilon: 0.6352093712757283, total steps: 11199
episode:460, reward: -50, mean reward: -2.42, score: -70.17913455785103, epsilon: 0.6346439422182364, total steps: 11228
episode:461, reward: -50, mean reward: -2.64, score: -58.088776555428126, epsilon: 0.6342153604931157, total steps: 11250
episode:462, reward: -50, mean reward: -1.72, score: -41.21662959858821, epsilon: 0.6337481751037934, total steps: 11274
episode:463, reward: -50, mean reward: -17.35, score: -52.05332841134256, epsilon: 0.6336898032049266, total steps: 11277
episode:464, reward: -50, mean reward: -2.1, score: -65.03926266876982, epsilon: 0.6330869685931387, total steps: 11308
episode:465, reward: -50, mean reward: -3.15, score: -56.776733413518684, epsilon: 0.6327372213466493, total steps: 11326
episode:466, reward: -50, mean reward: -3.05, score: -45.74348549751042, epsilon: 0.6324459255659898, total steps: 11341
episode:467, reward: 0.08494466829773728, mean reward: -0.8, score: -28.10903831064968, epsilon: 0.6317668015522011, total steps: 11376
episode:468, reward: -50, mean reward: -4.16, score: -62.46856649322274, epsilon: 0.6314759908601566, total steps: 11391
episode:469, reward: -0.8409665060599707, mean reward: -0.42, score: -14.811115177073134, epsilon: 0.6307979977770202, total steps: 11426
episode:470, reward: -50, mean reward: -6.36, score: -50.84348906465419, epsilon: 0.6306431389597064, total steps: 11434
episode:471, reward: 1.4475298645082262, mean reward: -0.24, score: -8.37765127025898, epsilon: 0.629966116970539, total steps: 11469
episode:472, reward: -0.066786974968295, mean reward: -0.82, score: -28.70842057543385, epsilon: 0.6292898843797867, total steps: 11504
episode:473, reward: -50, mean reward: -2.09, score: -45.950415056114565, epsilon: 0.6288652275244528, total steps: 11526
episode:474, reward: -50, mean reward: -1.9, score: -62.725501121029396, epsilon: 0.6282288258592623, total steps: 11559
episode:475, reward: -50, mean reward: -5.32, score: -69.14446835853337, epsilon: 0.6279783143161444, total steps: 11572
episode:476, reward: -50, mean reward: -1.86, score: -52.121971678766926, epsilon: 0.6274391195528137, total steps: 11600
episode:477, reward: -50, mean reward: -3.64, score: -43.73209227616877, epsilon: 0.6272081900939633, total steps: 11612
episode:478, reward: -50, mean reward: -3.02, score: -69.55719659977396, epsilon: 0.6267658334066221, total steps: 11635
episode:479, reward: 1.2765945266062886, mean reward: 0.19, score: 6.519745701576113, epsilon: 0.6260933323029039, total steps: 11670
episode:480, reward: -3.8233775062103064, mean reward: -0.63, score: -22.146897563461835, epsilon: 0.6254216153263104, total steps: 11705
episode:481, reward: -50, mean reward: -8.19, score: -49.164921701007614, epsilon: 0.6253065425109102, total steps: 11711
episode:482, reward: -2.0847878922288885, mean reward: -0.51, score: -17.82293881984245, epsilon: 0.6246357429204946, total steps: 11746
episode:483, reward: -1.0885166795188752, mean reward: -0.52, score: -18.374067980416896, epsilon: 0.6239657254732623, total steps: 11781
episode:484, reward: -50, mean reward: -4.43, score: -44.32033899199672, epsilon: 0.6237744354482132, total steps: 11791
episode:485, reward: -2.82932627981711, mean reward: -0.62, score: -21.65454004428588, epsilon: 0.6231054222737589, total steps: 11826
episode:486, reward: -50, mean reward: -1.7, score: -45.96827554830776, epsilon: 0.6225898594317918, total steps: 11853
episode:487, reward: -2.823179251047918, mean reward: -0.71, score: -24.79462958681148, epsilon: 0.6219222274568337, total steps: 11888
episode:488, reward: -50, mean reward: -5.4, score: -59.34934221479216, epsilon: 0.621712561081284, total steps: 11899
episode:489, reward: 0.5528255312258921, mean reward: -0.32, score: -11.172031044518434, epsilon: 0.6210459520242498, total steps: 11934
episode:490, reward: 0.7080354342955104, mean reward: 0.09, score: 3.317685696047448, epsilon: 0.6203801202242941, total steps: 11969
episode:491, reward: -50, mean reward: -3.72, score: -52.018702948819794, epsilon: 0.6201140049332535, total steps: 11983
episode:492, reward: -50, mean reward: -2.77, score: -47.043512113243736, epsilon: 0.6197910318481413, total steps: 12000
episode:493, reward: -50, mean reward: -11.95, score: -59.72704563169464, epsilon: 0.6196960745894914, total steps: 12005
episode:494, reward: 0.08495743768889952, mean reward: -0.03, score: -1.1808018584227682, epsilon: 0.6190318167282334, total steps: 12040
episode:495, reward: -50, mean reward: -3.58, score: -71.65335671427434, epsilon: 0.6186525886071671, total steps: 12060
episode:496, reward: -50, mean reward: -3.03, score: -57.49057757456811, epsilon: 0.618292555990079, total steps: 12079
episode:497, reward: -50, mean reward: -2.12, score: -40.31388384117477, epsilon: 0.6179327513214572, total steps: 12098
episode:498, reward: -1.2909142639804543, mean reward: -1.8, score: -63.01663342004744, epsilon: 0.6172705494711057, total steps: 12133
episode:499, reward: 0.5973026754299156, mean reward: 0.69, score: 24.309009179197716, epsilon: 0.6166091197390896, total steps: 12168
episode:500, reward: 1.0991701926651842, mean reward: -0.23, score: -7.946719690998094, epsilon: 0.6159484612251297, total steps: 12203
episode:501, reward: -50, mean reward: -4.92, score: -49.24436767748617, epsilon: 0.6157598431761426, total steps: 12213
episode:502, reward: -50, mean reward: -12.49, score: -49.96636151358118, epsilon: 0.6156844135591387, total steps: 12217
episode:503, reward: -50, mean reward: -3.64, score: -47.27132543670268, epsilon: 0.6154393367504066, total steps: 12230
episode:504, reward: -50, mean reward: -5.95, score: -53.54005146658409, epsilon: 0.6152697303916074, total steps: 12239
episode:505, reward: 1.3307219235926482, mean reward: 0.34, score: 12.044895602729952, epsilon: 0.6146106335873783, total steps: 12274
episode:506, reward: -1.5113941335287677, mean reward: -0.07, score: -2.4529891663468675, epsilon: 0.6139523052810432, total steps: 12309
episode:507, reward: -50, mean reward: -1.84, score: -57.17270784375603, epsilon: 0.6133698555497745, total steps: 12340
episode:508, reward: 0.5882405966734723, mean reward: 0.53, score: 18.380799856871107, epsilon: 0.6127129739737266, total steps: 12375
episode:509, reward: 1.6182302376261646, mean reward: -0.6, score: -20.875124831146337, epsilon: 0.6120568583126467, total steps: 12410
episode:510, reward: -0.33027233775311515, mean reward: -0.04, score: -1.2811236818334635, epsilon: 0.6114015076734886, total steps: 12445
episode:511, reward: 0.2574926820620931, mean reward: 0.07, score: 2.3939143013862747, epsilon: 0.6107469211642469, total steps: 12480
episode:512, reward: -50, mean reward: -3.45, score: -51.74159377327783, epsilon: 0.6104666177853492, total steps: 12495
episode:513, reward: -50, mean reward: -2.37, score: -45.02963180747517, epsilon: 0.6101117679750528, total steps: 12514
episode:514, reward: 0.19260018775628396, mean reward: 0.01, score: 0.440531949210623, epsilon: 0.6094586852847279, total steps: 12549
episode:515, reward: 0.5104516576784022, mean reward: -0.41, score: -14.279655933738866, epsilon: 0.6088063640799221, total steps: 12584
episode:516, reward: -50, mean reward: -3.04, score: -54.71518333999063, epsilon: 0.6084711808265055, total steps: 12602
episode:517, reward: -50, mean reward: -2.58, score: -77.4857374250656, epsilon: 0.6079129887882142, total steps: 12632
episode:518, reward: -50, mean reward: -6.21, score: -49.70134792406199, epsilon: 0.6077642318263471, total steps: 12640
episode:519, reward: -50, mean reward: -1.96, score: -56.83310614331168, epsilon: 0.6072253202514747, total steps: 12669
episode:520, reward: -50, mean reward: -3.34, score: -66.76273028659989, epsilon: 0.6068539605049766, total steps: 12689
episode:521, reward: -50, mean reward: -7.82, score: -54.72086044879791, epsilon: 0.6067240430718155, total steps: 12696
episode:522, reward: -1.223271623056462, mean reward: -0.73, score: -25.668034192923386, epsilon: 0.6060749104225722, total steps: 12731
episode:523, reward: -50, mean reward: -13.25, score: -52.9949787042616, epsilon: 0.6060007720438509, total steps: 12735
episode:524, reward: -50, mean reward: -0.8, score: -25.536874613057762, epsilon: 0.605408020743899, total steps: 12767
episode:525, reward: -50, mean reward: -3.51, score: -45.58941074628211, epsilon: 0.6051673960740205, total steps: 12780
episode:526, reward: 3.4850767295230014, mean reward: -0.05, score: -1.6361735683414906, epsilon: 0.6045200784539685, total steps: 12815
episode:527, reward: -50, mean reward: -5.4, score: -48.636056963252, epsilon: 0.6043537473813406, total steps: 12824
episode:528, reward: -1.9715239816497387, mean reward: -1.24, score: -43.41666102872554, epsilon: 0.6037073784645789, total steps: 12859
episode:529, reward: -50, mean reward: -2.49, score: -74.63013907204248, epsilon: 0.6031539478475421, total steps: 12889
episode:530, reward: -50, mean reward: -2.45, score: -58.80229811921404, epsilon: 0.6027116016513343, total steps: 12913
episode:531, reward: 0.560649364766391, mean reward: 0.26, score: 8.996994445774277, epsilon: 0.6020671474541206, total steps: 12948
episode:532, reward: 2.3298105651594483, mean reward: -0.13, score: -4.42681137380751, epsilon: 0.6014234446817205, total steps: 12983
episode:533, reward: -50, mean reward: -2.25, score: -69.80243387123917, epsilon: 0.6008539347530217, total steps: 13014
episode:534, reward: -3.4994673816933926, mean reward: 0.16, score: 5.774654270647801, epsilon: 0.6002116465701021, total steps: 13049
episode:535, reward: -50, mean reward: -8.2, score: -57.374834888583536, epsilon: 0.600083278829388, total steps: 13056
episode:536, reward: -50, mean reward: -4.32, score: -60.471638280510234, epsilon: 0.5998266331879082, total steps: 13070
episode:537, reward: -50, mean reward: -2.69, score: -32.2280318323337, epsilon: 0.5996067465148994, total steps: 13082
episode:538, reward: -50, mean reward: -3.12, score: -78.08256870413055, epsilon: 0.5991489316754807, total steps: 13107
episode:539, reward: -1.4730854786784278, mean reward: -0.44, score: -15.445341002827263, epsilon: 0.5985086315029199, total steps: 13142
episode:540, reward: -50, mean reward: -3.15, score: -53.60473057748658, epsilon: 0.5981978979945439, total steps: 13159
episode:541, reward: -50, mean reward: -2.3, score: -66.82950040891438, epsilon: 0.5976682294075452, total steps: 13188
episode:542, reward: -2.28766352242846, mean reward: 0.14, score: 4.9992488220912605, epsilon: 0.5970296557136553, total steps: 13223
episode:543, reward: -50, mean reward: -6.55, score: -58.91214030642752, epsilon: 0.5968655714308141, total steps: 13232
episode:544, reward: -50, mean reward: -2.08, score: -51.913130909091535, epsilon: 0.5964100399524329, total steps: 13257
episode:545, reward: 3.081613525440929, mean reward: -0.24, score: -8.551384169812422, epsilon: 0.5957729332903058, total steps: 13292
episode:546, reward: -1.0756725914159233, mean reward: -0.52, score: -18.274749286413254, epsilon: 0.5951365694858665, total steps: 13327
episode:547, reward: -50, mean reward: -2.69, score: -48.36158969748726, epsilon: 0.5948095856491354, total steps: 13345
episode:548, reward: -50, mean reward: -1.37, score: -46.56096154289776, epsilon: 0.5941924845420798, total steps: 13379
episode:549, reward: -50, mean reward: -13.81, score: -55.251763934497376, epsilon: 0.5941199303811924, total steps: 13383
episode:550, reward: -50, mean reward: -1.77, score: -49.57481539601923, epsilon: 0.5936123220335808, total steps: 13411
episode:551, reward: -50, mean reward: -11.72, score: -58.59486180334213, epsilon: 0.5935217275296603, total steps: 13416
episode:552, reward: -50, mean reward: -2.36, score: -47.20834909447859, epsilon: 0.5931595004670771, total steps: 13436
episode:553, reward: -50, mean reward: -3.71, score: -40.825386703854974, epsilon: 0.592960378491499, total steps: 13447
episode:554, reward: -50, mean reward: -1.62, score: -51.867532771251206, epsilon: 0.5923815295287717, total steps: 13479
episode:555, reward: -50, mean reward: -0.78, score: -25.67997026208681, epsilon: 0.5917852378668301, total steps: 13512
episode:556, reward: -50, mean reward: -4.37, score: -56.84180611342063, epsilon: 0.5915505151240218, total steps: 13525
episode:557, reward: 1.4406503780652145, mean reward: 0.22, score: 7.740927216432112, epsilon: 0.5909190746016368, total steps: 13560
episode:558, reward: -50, mean reward: -7.74, score: -46.465568245892115, epsilon: 0.5908109016043768, total steps: 13566
episode:559, reward: -0.30354145648431086, mean reward: -0.16, score: -5.505136884350577, epsilon: 0.590180323461279, total steps: 13601
episode:560, reward: -0.4463469521482182, mean reward: -0.13, score: -4.624290493585136, epsilon: 0.589550480563705, total steps: 13636
episode:561, reward: -1.2320216263630357, mean reward: -0.21, score: -7.389909020315741, epsilon: 0.5889213720543683, total steps: 13671
episode:562, reward: 3.069284937129737, mean reward: 0.44, score: 15.511675052094432, epsilon: 0.5882929970769825, total steps: 13706
episode:563, reward: -50, mean reward: -1.77, score: -58.458262247064226, epsilon: 0.5877012003280825, total steps: 13739
episode:564, reward: -50, mean reward: -3.45, score: -51.821355130154956, epsilon: 0.5874324169293678, total steps: 13754
episode:565, reward: 1.9057587858304146, mean reward: -0.58, score: -20.3000276219459, epsilon: 0.5868057780533715, total steps: 13789
episode:566, reward: -50, mean reward: -1.89, score: -45.24659165577907, epsilon: 0.5863765051629796, total steps: 13813
episode:567, reward: -0.7586466075820226, mean reward: -0.44, score: -15.308396963964299, epsilon: 0.585751097465717, total steps: 13848
episode:568, reward: -50, mean reward: -3.83, score: -49.82370392417073, epsilon: 0.5855189889506255, total steps: 13861
episode:569, reward: -0.7117495099100779, mean reward: -0.7, score: -24.52812789689716, epsilon: 0.5848945811055835, total steps: 13896
episode:570, reward: 2.520769810743616, mean reward: 0.84, score: 29.264164308785638, epsilon: 0.5842709013115815, total steps: 13931
episode:571, reward: -50, mean reward: -3.73, score: -59.73462016016313, epsilon: 0.5839860328025702, total steps: 13947
episode:572, reward: 2.0968685823951034, mean reward: 0.59, score: 20.569782434087642, epsilon: 0.5833634123635113, total steps: 13982
episode:573, reward: -50, mean reward: -6.57, score: -59.132349234669334, epsilon: 0.5832034273387559, total steps: 13991
episode:574, reward: 2.381118256732833, mean reward: -0.16, score: -5.496397766644549, epsilon: 0.5825817194070052, total steps: 14026
episode:575, reward: -50, mean reward: -1.96, score: -45.03384653490261, epsilon: 0.5821735632353178, total steps: 14049
episode:576, reward: -1.1480709386649153, mean reward: 0.15, score: 5.27388734909843, epsilon: 0.5815530561110807, total steps: 14084
episode:577, reward: -50, mean reward: -1.43, score: -47.341050686508254, epsilon: 0.5809686692210736, total steps: 14117
episode:578, reward: -50, mean reward: -3.46, score: -51.930424487116625, epsilon: 0.5807032512464863, total steps: 14132
episode:579, reward: -1.7716218225530156, mean reward: -1.18, score: -41.25252675759421, epsilon: 0.5800844584859961, total steps: 14167
episode:580, reward: -50, mean reward: -6.04, score: -48.35307328055518, epsilon: 0.579943121476172, total steps: 14175
episode:581, reward: -50, mean reward: -3.19, score: -57.44259939147494, epsilon: 0.5796252509739731, total steps: 14193
episode:582, reward: -50, mean reward: -3.53, score: -45.94867266875602, epsilon: 0.5793957964172955, total steps: 14206
episode:583, reward: -50, mean reward: -3.69, score: -48.00761546800311, epsilon: 0.5791664412693858, total steps: 14219
episode:584, reward: -50, mean reward: -1.46, score: -51.003788782208915, epsilon: 0.578549440408391, total steps: 14254
episode:585, reward: -1.7065422016419234, mean reward: 0.27, score: 9.434745867924931, epsilon: 0.5779331589619939, total steps: 14289
episode:586, reward: -0.6394078057005572, mean reward: -0.13, score: -4.404035196578434, epsilon: 0.5773175960913669, total steps: 14324
episode:587, reward: -50, mean reward: -2.64, score: -52.81312553574347, epsilon: 0.5769661681829579, total steps: 14344
episode:588, reward: -0.012441998571688373, mean reward: 0.24, score: 8.234781839507036, epsilon: 0.5763517328104046, total steps: 14379
episode:589, reward: -2.556678870768337, mean reward: -0.13, score: -4.510147739195531, epsilon: 0.5757380138611246, total steps: 14414
episode:590, reward: -50, mean reward: -2.34, score: -53.9289910161404, epsilon: 0.5753351025195805, total steps: 14437
episode:591, reward: -2.3172988820500393, mean reward: -0.04, score: -1.2641829944743392, epsilon: 0.5747225689473686, total steps: 14472
episode:592, reward: 0.05694783902347922, mean reward: -0.06, score: -2.2009943465907043, epsilon: 0.5741107495809566, total steps: 14507
episode:593, reward: -50, mean reward: -2.47, score: -42.05420988519535, epsilon: 0.5738138376225276, total steps: 14524
episode:594, reward: -50, mean reward: -4.38, score: -39.4416854398977, epsilon: 0.5736567170405065, total steps: 14533
episode:595, reward: 1.2476424542709026, mean reward: 0.0, score: 0.07034198015711013, epsilon: 0.5730461404428963, total steps: 14568
episode:596, reward: 1.2929864489865395, mean reward: -0.33, score: -11.558760854015048, epsilon: 0.5724362757692804, total steps: 14603
episode:597, reward: -50, mean reward: -1.02, score: -32.73548596671753, epsilon: 0.5718793075110064, total steps: 14635
episode:598, reward: -50, mean reward: -5.65, score: -50.877814337492396, epsilon: 0.5717227672009737, total steps: 14644
episode:599, reward: 0.285249986585427, mean reward: 0.18, score: 6.397464207830069, epsilon: 0.5711144455625277, total steps: 14679
episode:600, reward: 0.35091648951643606, mean reward: -0.3, score: -10.371836964352184, epsilon: 0.5705068332188242, total steps: 14714
episode:601, reward: -1.7305136829676826, mean reward: -0.21, score: -7.197963110419124, epsilon: 0.5698999293428353, total steps: 14749
episode:602, reward: -50, mean reward: -17.35, score: -52.05321590006443, epsilon: 0.569847941949314, total steps: 14752
episode:603, reward: 0.011063291031348399, mean reward: 0.06, score: 2.1293025640036376, epsilon: 0.5692418063315682, total steps: 14787
episode:604, reward: -50, mean reward: -1.58, score: -33.28302074300913, epsilon: 0.5688784642517006, total steps: 14808
episode:605, reward: 0.970579606688176, mean reward: -0.83, score: -29.218658944106778, epsilon: 0.5682734590317419, total steps: 14843
episode:606, reward: 1.8691089466388178, mean reward: 0.46, score: 16.237267683517928, epsilon: 0.5676691592396268, total steps: 14878
episode:607, reward: -50, mean reward: -2.97, score: -53.53495074962552, epsilon: 0.5673586509058984, total steps: 14896
episode:608, reward: -0.5177462708710436, mean reward: 0.06, score: 2.2406871773713704, epsilon: 0.5667554177675944, total steps: 14931
episode:609, reward: -0.326879345268992, mean reward: -0.51, score: -17.849540822390054, epsilon: 0.5661528879909112, total steps: 14966
episode:610, reward: -50, mean reward: -0.79, score: -24.442372695270848, epsilon: 0.5656198054800523, total steps: 14997
episode:611, reward: -50, mean reward: -2.12, score: -50.9567683147265, epsilon: 0.5652074745900153, total steps: 15021
episode:612, reward: 1.535002863010419, mean reward: 0.5, score: 17.402655900922724, epsilon: 0.5646067496939874, total steps: 15056
episode:613, reward: -1.2983437120932138, mean reward: 0.19, score: 6.571044357210155, epsilon: 0.5640067252350038, total steps: 15091
episode:614, reward: -2.1397685342712407, mean reward: -0.07, score: -2.5121439831389125, epsilon: 0.5634074003963645, total steps: 15126
episode:615, reward: -50, mean reward: -4.44, score: -44.38419702027281, epsilon: 0.5632362931156968, total steps: 15136
episode:616, reward: -50, mean reward: -2.26, score: -45.2144509801341, epsilon: 0.5628942496141217, total steps: 15156
episode:617, reward: -1.5046572737685437, mean reward: -0.2, score: -7.042664610958639, epsilon: 0.5622962219068997, total steps: 15191
episode:618, reward: 0.38767002387771754, mean reward: -0.23, score: -8.152254922314484, epsilon: 0.5616988914918366, total steps: 15226
episode:619, reward: 2.42762506745089, mean reward: 0.34, score: 11.891261022315035, epsilon: 0.561102257555899, total steps: 15261
episode:620, reward: 2.408714321092617, mean reward: -0.54, score: -19.028020847918185, epsilon: 0.5605063192870022, total steps: 15296
episode:621, reward: -50, mean reward: -3.52, score: -56.3468121188433, epsilon: 0.5602341218424866, total steps: 15312
episode:622, reward: -2.743651381860701, mean reward: 0.37, score: 12.910022839306237, epsilon: 0.5596391958080038, total steps: 15347
episode:623, reward: -50, mean reward: -3.95, score: -47.429419178123084, epsilon: 0.5594353808953806, total steps: 15359
episode:624, reward: 1.952037774206815, mean reward: 0.02, score: 0.6304273839752454, epsilon: 0.5588413861819599, total steps: 15394
episode:625, reward: -50, mean reward: -17.35, score: -52.05392167626135, epsilon: 0.5587905045874638, total steps: 15397
episode:626, reward: -50, mean reward: -1.6, score: -43.27255405943677, epsilon: 0.5583327991316853, total steps: 15424
episode:627, reward: -0.6141412594968472, mean reward: 0.08, score: 2.8534638229562006, epsilon: 0.5577400900135792, total steps: 15459
episode:628, reward: -50, mean reward: -1.99, score: -69.73057097654933, epsilon: 0.5571480719862295, total steps: 15494
episode:629, reward: -1.7266456221154272, mean reward: -0.68, score: -23.888838641638102, epsilon: 0.5565567442438338, total steps: 15529
episode:630, reward: -50, mean reward: -3.32, score: -39.87301857868147, epsilon: 0.5563541620652731, total steps: 15541
episode:631, reward: -50, mean reward: -1.74, score: -55.78319907111501, epsilon: 0.555814338915933, total steps: 15573
episode:632, reward: -50, mean reward: -1.05, score: -29.276370994094435, epsilon: 0.5553424657746653, total steps: 15601
episode:633, reward: -50, mean reward: -0.83, score: -20.754053871631612, epsilon: 0.5549215224705898, total steps: 15626
episode:634, reward: -0.013196349409497543, mean reward: -0.15, score: -5.3878375757385015, epsilon: 0.5543327908545942, total steps: 15661
episode:635, reward: -50, mean reward: -5.42, score: -59.60209817586673, epsilon: 0.5541479027295085, total steps: 15672
episode:636, reward: -2.9272675460252913, mean reward: -0.06, score: -2.1368060278889516, epsilon: 0.5535600731435911, total steps: 15707
episode:637, reward: 1.0424560729486245, mean reward: 0.61, score: 21.48388009378698, epsilon: 0.5529729289589619, total steps: 15742
episode:638, reward: -50, mean reward: -6.2, score: -49.57328564877426, epsilon: 0.5528388207264652, total steps: 15750
episode:639, reward: -50, mean reward: -3.34, score: -70.10012301981095, epsilon: 0.5524869567187273, total steps: 15771
episode:640, reward: 0.20978241586533386, mean reward: 0.06, score: 1.9884997260110708, epsilon: 0.551901063773229, total steps: 15806
episode:641, reward: 1.7090834373013593, mean reward: 0.16, score: 5.659366124239966, epsilon: 0.5513158539709229, total steps: 15841
episode:642, reward: -50, mean reward: -2.25, score: -40.54839141044786, epsilon: 0.5510151546773494, total steps: 15859
episode:643, reward: -1.0842653938025535, mean reward: 0.23, score: 7.9070172422437395, epsilon: 0.5504309778329792, total steps: 15894
episode:644, reward: 1.3165822942360421, mean reward: 0.3, score: 10.543583054092693, epsilon: 0.5498474821308504, total steps: 15929
episode:645, reward: -50, mean reward: -1.74, score: -52.21572640330328, epsilon: 0.5493478844891736, total steps: 15959
episode:646, reward: -50, mean reward: -0.83, score: -21.62218521468057, epsilon: 0.548915303801324, total steps: 15985
episode:647, reward: -50, mean reward: -0.73, score: -25.64747204296208, epsilon: 0.5483335753544663, total steps: 16020
episode:648, reward: 2.964438465933256, mean reward: -0.15, score: -5.112837357469658, epsilon: 0.5477525251950518, total steps: 16055
episode:649, reward: -50, mean reward: -5.8, score: -58.017581198273575, epsilon: 0.5475866353364993, total steps: 16065
episode:650, reward: -0.20491200696247347, mean reward: 0.65, score: 22.703299301424153, epsilon: 0.5470064560989693, total steps: 16100
episode:651, reward: 0.2505510794416921, mean reward: 0.15, score: 5.183321768627508, epsilon: 0.5464269533425258, total steps: 16135
episode:652, reward: -2.2198387487241007, mean reward: 0.18, score: 6.157647776550704, epsilon: 0.5458481262784008, total steps: 16170
episode:653, reward: -1.8999818653441878, mean reward: 0.26, score: 9.073382972160829, epsilon: 0.5452699741187466, total steps: 16205
episode:654, reward: -1.629235290659011, mean reward: 0.33, score: 11.430466713795, epsilon: 0.5446924960766336, total steps: 16240
episode:655, reward: -0.9356127689803202, mean reward: -0.61, score: -21.244620171363323, epsilon: 0.54411569136605, total steps: 16275
episode:656, reward: 1.6015628672947742, mean reward: 0.56, score: 19.461437591694022, epsilon: 0.5435395592019003, total steps: 16310
episode:657, reward: -50, mean reward: -1.72, score: -56.765916435267, epsilon: 0.5429969641687582, total steps: 16343
episode:658, reward: 1.330145897884364, mean reward: 0.41, score: 14.51086573314933, epsilon: 0.5424221364252786, total steps: 16378
episode:659, reward: -1.3376172714210668, mean reward: -0.43, score: -15.133458370034276, epsilon: 0.5418479789231164, total steps: 16413
episode:660, reward: -1.1652461612801233, mean reward: 0.63, score: 21.994511807167697, epsilon: 0.5412744908807793, total steps: 16448
episode:661, reward: -50, mean reward: -0.93, score: -29.660523470415256, epsilon: 0.5407507441384279, total steps: 16480
episode:662, reward: -50, mean reward: -0.85, score: -26.368713157879085, epsilon: 0.5402438969522977, total steps: 16511
episode:663, reward: -50, mean reward: -1.71, score: -35.82661729323152, epsilon: 0.5399008463061651, total steps: 16532
episode:664, reward: 0.59073657965547, mean reward: 0.28, score: 9.766036721213993, epsilon: 0.539329628593931, total steps: 16567
episode:665, reward: 2.248599648111991, mean reward: 0.31, score: 10.728055359360326, epsilon: 0.5387590769137669, total steps: 16602
episode:666, reward: -50, mean reward: -4.25, score: -46.76116112619462, epsilon: 0.5385798981036878, total steps: 16613
episode:667, reward: 0.14513094548891559, mean reward: -0.23, score: -7.903449100797417, epsilon: 0.5380102205990608, total steps: 16648
episode:668, reward: -50, mean reward: -0.87, score: -21.640262369267447, epsilon: 0.5376037148161624, total steps: 16673
episode:669, reward: -0.833334153468769, mean reward: 0.64, score: 22.36826999165197, epsilon: 0.5370351755279488, total steps: 16708
episode:670, reward: -50, mean reward: -0.8, score: -20.76154207832039, epsilon: 0.5366132612317617, total steps: 16734
episode:671, reward: 0.541498771931856, mean reward: -0.47, score: -16.282003641557736, epsilon: 0.5360458767989332, total steps: 16769
episode:672, reward: -2.540405852698541, mean reward: -1.11, score: -38.91322261825542, epsilon: 0.5354791539286231, total steps: 16804
episode:673, reward: 2.534545063360042, mean reward: 0.27, score: 9.600446302265453, epsilon: 0.5349130918494587, total steps: 16839
episode:674, reward: -1.3799544812134457, mean reward: 0.38, score: 13.430237000514097, epsilon: 0.5343476897909664, total steps: 16874
episode:675, reward: 0.9844969498142291, mean reward: -0.16, score: -5.487127032555122, epsilon: 0.533782946983571, total steps: 16909
episode:676, reward: -1.5237087802397866, mean reward: -0.0, score: -0.0005783739353262263, epsilon: 0.5332188626585949, total steps: 16944
episode:677, reward: 0.6039422580093969, mean reward: -0.32, score: -11.304772158831895, epsilon: 0.5326554360482564, total steps: 16979
episode:678, reward: -1.229476526647204, mean reward: -0.43, score: -14.962936057890744, epsilon: 0.5320926663856692, total steps: 17014
episode:679, reward: -0.6842955528018706, mean reward: 0.3, score: 10.654273268890819, epsilon: 0.5315305529048414, total steps: 17049
episode:680, reward: 2.441953983444108, mean reward: 0.34, score: 11.994194147343336, epsilon: 0.5309690948406738, total steps: 17084
episode:681, reward: -0.8420615777954765, mean reward: 0.41, score: 14.359402844570752, epsilon: 0.5304082914289594, total steps: 17119
episode:682, reward: -50, mean reward: -3.76, score: -48.89961681613954, epsilon: 0.5302001596011597, total steps: 17132
episode:683, reward: 2.5023305765935504, mean reward: 0.53, score: 18.650288317903374, epsilon: 0.5296402527574585, total steps: 17167
episode:684, reward: -50, mean reward: -6.58, score: -46.07153070336176, epsilon: 0.5295283497543398, total steps: 17174
episode:685, reward: 1.5695170390405906, mean reward: -0.02, score: -0.6472756274900178, epsilon: 0.5289692262317671, total steps: 17209
episode:686, reward: -50, mean reward: -12.42, score: -49.669628057314014, epsilon: 0.5289053679255845, total steps: 17213
episode:687, reward: -2.5657697628829226, mean reward: 0.53, score: 18.4580209529594, epsilon: 0.5283469707913364, total steps: 17248
episode:688, reward: -50, mean reward: -0.96, score: -27.968424266761446, epsilon: 0.5278847921419086, total steps: 17277
episode:689, reward: 1.342451438097612, mean reward: 0.02, score: 0.6432497373088779, epsilon: 0.5273275849851196, total steps: 17312
episode:690, reward: -50, mean reward: -3.17, score: -34.85863058362307, epsilon: 0.5271525969537246, total steps: 17323
episode:691, reward: -50, mean reward: -1.03, score: -28.888299488886787, epsilon: 0.5267074622917236, total steps: 17351
episode:692, reward: -50, mean reward: -3.32, score: -46.50433529564879, epsilon: 0.5264850507093931, total steps: 17365
episode:693, reward: 0.4121540334761846, mean reward: 0.6, score: 20.867662957167028, epsilon: 0.5259294756320438, total steps: 17400
episode:694, reward: 0.19943027042037897, mean reward: 0.18, score: 6.286384037325774, epsilon: 0.5253745483476654, total steps: 17435
episode:695, reward: -50, mean reward: -2.8, score: -50.323763423432325, epsilon: 0.5250894091689646, total steps: 17453
episode:696, reward: -1.8139362934255985, mean reward: -0.19, score: -6.47582543494417, epsilon: 0.5245354613906369, total steps: 17488
episode:697, reward: 2.6236894728425852, mean reward: 0.58, score: 20.3704844963097, epsilon: 0.5239821595078715, total steps: 17523
episode:698, reward: -1.9644967234830801, mean reward: -0.07, score: -2.4886487414325416, epsilon: 0.5234295027675631, total steps: 17558
episode:699, reward: -50, mean reward: -3.6, score: -39.54582406632326, epsilon: 0.5232559437709756, total steps: 17569
episode:700, reward: -50, mean reward: -1.0, score: -26.919422638867644, epsilon: 0.5228302050327512, total steps: 17596
episode:701, reward: -3.5018437152416766, mean reward: -0.39, score: -13.54257041395556, epsilon: 0.5222788914556663, total steps: 17631
episode:702, reward: -50, mean reward: -5.08, score: -60.93243315439884, epsilon: 0.5220900176763582, total steps: 17643
episode:703, reward: -1.075590549128151, mean reward: 0.13, score: 4.652904293553348, epsilon: 0.5215395671476462, total steps: 17678
episode:704, reward: -50, mean reward: -3.64, score: -58.22105457556779, epsilon: 0.5212881464299851, total steps: 17694
episode:705, reward: -50, mean reward: -4.45, score: -48.96096773510226, epsilon: 0.5211153724534588, total steps: 17705
episode:706, reward: -50, mean reward: -1.96, score: -47.04233111709087, epsilon: 0.5207386308722215, total steps: 17729
episode:707, reward: -50, mean reward: -2.1, score: -58.6744019949092, epsilon: 0.5202994797857935, total steps: 17757
episode:708, reward: -0.8808485519105318, mean reward: -0.43, score: -14.891762941080657, epsilon: 0.5197511169998671, total steps: 17792
episode:709, reward: 0.1897006227355007, mean reward: 0.31, score: 10.751902784177076, epsilon: 0.519203393597478, total steps: 17827
episode:710, reward: -50, mean reward: -0.83, score: -25.78877559939636, epsilon: 0.5187188005069773, total steps: 17858
episode:711, reward: -50, mean reward: -0.74, score: -19.969708516259004, epsilon: 0.5182971433606987, total steps: 17885
episode:712, reward: 0.4371595721307244, mean reward: -0.34, score: -11.773547731812812, epsilon: 0.5177511152717634, total steps: 17920
episode:713, reward: -50, mean reward: -2.34, score: -51.47013974538089, epsilon: 0.5174082235295695, total steps: 17942
episode:714, reward: -1.1645696417170086, mean reward: 0.47, score: 16.280026120409588, epsilon: 0.5168632319090466, total steps: 17977
episode:715, reward: -50, mean reward: -1.2, score: -28.85478637799457, epsilon: 0.5164898906799226, total steps: 18001
episode:716, reward: -0.4120992328205091, mean reward: 1.02, score: 35.56753664177276, epsilon: 0.5159459698229905, total steps: 18036
episode:717, reward: -50, mean reward: -2.35, score: -51.63935277447098, epsilon: 0.5156044013688609, total steps: 18058
episode:718, reward: -50, mean reward: -7.35, score: -58.813930406309936, epsilon: 0.5154802567485142, total steps: 18066
episode:719, reward: -0.38923806048012466, mean reward: 0.41, score: 14.291056986743683, epsilon: 0.5149375131109907, total steps: 18101
episode:720, reward: 0.7206397697934506, mean reward: 0.35, score: 12.086597952190345, epsilon: 0.514395402305154, total steps: 18136
episode:721, reward: -50, mean reward: -10.67, score: -53.351878401762775, epsilon: 0.5143180095210143, total steps: 18141
episode:722, reward: -50, mean reward: -2.81, score: -39.3448978953449, epsilon: 0.5141013783344462, total steps: 18155
episode:723, reward: -50, mean reward: -2.32, score: -48.72644201148492, epsilon: 0.5137766210479232, total steps: 18176
episode:724, reward: -1.2004625740035522, mean reward: 0.1, score: 3.5835852621483753, epsilon: 0.5132358638264157, total steps: 18211
episode:725, reward: 2.6086861449776393, mean reward: 0.86, score: 30.004934493392682, epsilon: 0.5126957371204611, total steps: 18246
episode:726, reward: -50, mean reward: -6.12, score: -61.150145803851785, epsilon: 0.5125415309105504, total steps: 18256
episode:727, reward: -50, mean reward: -0.92, score: -30.476123372585704, epsilon: 0.5120330149615961, total steps: 18289
episode:728, reward: -50, mean reward: -2.12, score: -55.043299421306074, epsilon: 0.5116327598175782, total steps: 18315
episode:729, reward: -50, mean reward: -3.76, score: -45.062486075513306, epsilon: 0.5114481436393483, total steps: 18327
episode:730, reward: -1.1723801014601065, mean reward: -0.71, score: -24.85274367633434, epsilon: 0.5109101013907754, total steps: 18362
episode:731, reward: -50, mean reward: -1.34, score: -30.883738775992526, epsilon: 0.5105568724014566, total steps: 18385
episode:732, reward: -50, mean reward: -1.63, score: -40.8705331978758, epsilon: 0.5101732348789577, total steps: 18410
episode:733, reward: 0.6887833040040903, mean reward: 0.46, score: 15.92875056531227, epsilon: 0.5096366791566297, total steps: 18445
episode:734, reward: -50, mean reward: -2.62, score: -47.143474173553614, epsilon: 0.5093609798671935, total steps: 18463
episode:735, reward: -50, mean reward: -0.76, score: -22.096580127849933, epsilon: 0.5089171454745066, total steps: 18492
episode:736, reward: -50, mean reward: -3.23, score: -48.49836658509108, epsilon: 0.5086877442568528, total steps: 18507
episode:737, reward: 0.13618225756184188, mean reward: -0.47, score: -16.42366649696413, epsilon: 0.5081529205963514, total steps: 18542
episode:738, reward: -0.7963082637672301, mean reward: 0.91, score: 31.776163967863283, epsilon: 0.5076187205329514, total steps: 18577
episode:739, reward: 0.8365581590144586, mean reward: 0.2, score: 6.83524478900469, epsilon: 0.5070851433395474, total steps: 18612
episode:740, reward: 1.1383221589038328, mean reward: 0.12, score: 4.067815691740549, epsilon: 0.506552188289881, total steps: 18647
episode:741, reward: 0.3187451576670526, mean reward: 0.09, score: 3.203537157986432, epsilon: 0.5060198546585416, total steps: 18682
episode:742, reward: 2.032129708849027, mean reward: 0.68, score: 23.862105656672668, epsilon: 0.5054881417209636, total steps: 18717
episode:743, reward: -50, mean reward: -14.24, score: -56.97408055264353, epsilon: 0.5054274140173376, total steps: 18721
episode:744, reward: -50, mean reward: -0.81, score: -27.471856191999706, epsilon: 0.5049115553232606, total steps: 18755
episode:745, reward: -50, mean reward: -1.99, score: -49.73892972544576, epsilon: 0.5045326202720251, total steps: 18780
episode:746, reward: -50, mean reward: -1.73, score: -34.64745318071661, epsilon: 0.5042296995099836, total steps: 18800
episode:747, reward: -50, mean reward: -1.83, score: -54.76286501827815, epsilon: 0.5037756968496374, total steps: 18830
episode:748, reward: -50, mean reward: -5.36, score: -53.641234965949536, epsilon: 0.5036244634909809, total steps: 18840
episode:749, reward: -0.8633182035974869, mean reward: -0.09, score: -3.005221954279648, epsilon: 0.5030955435468688, total steps: 18875
episode:750, reward: -0.5112249101700002, mean reward: 0.76, score: 26.54540649472287, epsilon: 0.5025672403162053, total steps: 18910
episode:751, reward: -1.0686502155552944, mean reward: 0.5, score: 17.51152666463244, epsilon: 0.5020395530799109, total steps: 18945
episode:752, reward: -50, mean reward: -1.69, score: -59.287937517365805, epsilon: 0.5015124811197447, total steps: 18980
episode:753, reward: 1.0492177847115727, mean reward: -0.24, score: -8.435463444231743, epsilon: 0.5009860237183031, total steps: 19015
episode:754, reward: -50, mean reward: -2.3, score: -80.62730368495369, epsilon: 0.5004601801590189, total steps: 19050
episode:755, reward: -50, mean reward: -0.63, score: -13.770165111024397, epsilon: 0.5001299637877037, total steps: 19072
episode:756, reward: 1.913210525670621, mean reward: 0.26, score: 9.07583836689119, epsilon: 0.4996051183826355, total steps: 19107
episode:757, reward: 0.15879696183492342, mean reward: 0.07, score: 2.6039079600874686, epsilon: 0.4990808849401588, total steps: 19142
episode:758, reward: -50, mean reward: -12.73, score: -50.935034956980985, epsilon: 0.49902101148048617, total steps: 19146
episode:759, reward: 2.574798563472939, mean reward: 0.37, score: 13.04515396014952, epsilon: 0.4984974590986994, total steps: 19181
episode:760, reward: 3.0281033202094534, mean reward: 1.13, score: 39.491344441886724, epsilon: 0.49797451717185676, total steps: 19216
episode:761, reward: -1.5057681666416158, mean reward: 0.07, score: 2.427512859407244, epsilon: 0.497452184988176, total steps: 19251
episode:762, reward: -50, mean reward: -1.79, score: -39.37320088898062, epsilon: 0.4971241736713673, total steps: 19273
episode:763, reward: -2.4624598259845243, mean reward: 0.94, score: 33.04060843992002, epsilon: 0.49660283297662294, total steps: 19308
episode:764, reward: 1.8120667362801726, mean reward: 0.62, score: 21.567550639025967, epsilon: 0.49608210015802556, total steps: 19343
episode:765, reward: -50, mean reward: -1.24, score: -38.48905381009598, epsilon: 0.49562138673079464, total steps: 19374
episode:766, reward: -50, mean reward: -1.01, score: -23.20687963740579, epsilon: 0.4952798745973466, total steps: 19397
episode:767, reward: 2.440130540063649, mean reward: 0.21, score: 7.394165336661359, epsilon: 0.49476068433019516, total steps: 19432
episode:768, reward: 0.8522294679958975, mean reward: 1.15, score: 40.41634142148547, epsilon: 0.4942420994318216, total steps: 19467
episode:769, reward: -50, mean reward: -0.93, score: -28.846422658943794, epsilon: 0.49378328635665675, total steps: 19498
episode:770, reward: -50, mean reward: -0.89, score: -31.20834847370608, epsilon: 0.4932658410910041, total steps: 19533
episode:771, reward: 1.828228695054321, mean reward: -0.17, score: -6.043493317897656, epsilon: 0.4927489991594812, total steps: 19568
episode:772, reward: 1.396547406397076, mean reward: -0.2, score: -6.900695413574795, epsilon: 0.4922327598586089, total steps: 19603
episode:773, reward: -0.29938352683058156, mean reward: 0.76, score: 26.700020186465338, epsilon: 0.491717122485728, total steps: 19638
episode:774, reward: 2.6947312780039567, mean reward: 0.56, score: 19.500225413018683, epsilon: 0.4912020863389987, total steps: 19673
episode:775, reward: 0.6415000267477069, mean reward: -0.06, score: -1.9663401607935214, epsilon: 0.4906876507173995, total steps: 19708
episode:776, reward: -50, mean reward: -0.85, score: -20.505902274156654, epsilon: 0.49033524157927594, total steps: 19732
episode:777, reward: -50, mean reward: -1.59, score: -49.207111649765494, epsilon: 0.4898804635054491, total steps: 19763
episode:778, reward: -2.7681253745110155, mean reward: -0.72, score: -25.091941915135322, epsilon: 0.48936756887806754, total steps: 19798
episode:779, reward: -50, mean reward: -5.56, score: -44.48751977327768, epsilon: 0.48925041981360284, total steps: 19806
episode:780, reward: -50, mean reward: -0.61, score: -17.663767451435064, epsilon: 0.488826016235894, total steps: 19835
episode:781, reward: -0.22930572585678988, mean reward: -0.37, score: -12.84316020966105, epsilon: 0.4883143510796627, total steps: 19870
episode:782, reward: -0.10397557497060461, mean reward: -0.09, score: -3.025666040206403, epsilon: 0.4878032825180325, total steps: 19905
episode:783, reward: -50, mean reward: -1.7, score: -52.727876868569666, epsilon: 0.48735111945058285, total steps: 19936
episode:784, reward: -50, mean reward: -2.92, score: -49.57421612048833, epsilon: 0.487103357355451, total steps: 19953
episode:785, reward: -1.0708902730053182, mean reward: 0.49, score: 17.058634594108497, epsilon: 0.48659370079600434, total steps: 19988
episode:786, reward: -50, mean reward: -0.71, score: -21.386059974491616, epsilon: 0.4861573253193113, total steps: 20018
episode:787, reward: -50, mean reward: -1.77, score: -60.298096642234384, epsilon: 0.4856632936880868, total steps: 20052
episode:788, reward: 1.3020594758328627, mean reward: 0.39, score: 13.621899638802915, epsilon: 0.4851553162232563, total steps: 20087
episode:789, reward: -50, mean reward: -4.22, score: -59.032206291042684, epsilon: 0.48495229111856103, total steps: 20101
episode:790, reward: -50, mean reward: -1.72, score: -41.369530655358176, epsilon: 0.48460446843329086, total steps: 20125
episode:791, reward: 0.4942451958135905, mean reward: 0.33, score: 11.558074848224635, epsilon: 0.4840977255442817, total steps: 20160
episode:792, reward: 1.2071308436773904, mean reward: 0.43, score: 15.188088229844226, epsilon: 0.4835915735105772, total steps: 20195
episode:793, reward: -50, mean reward: -12.74, score: -50.94592409766156, epsilon: 0.4835337651547518, total steps: 20199
episode:794, reward: 1.492830900069606, mean reward: 1.16, score: 40.734240353756974, epsilon: 0.4830282706911779, total steps: 20234
episode:795, reward: -1.0212426009342437, mean reward: -0.06, score: -1.9870664684714825, epsilon: 0.4825233656272614, total steps: 20269
episode:796, reward: 2.2658401353640443, mean reward: -0.22, score: -7.738321210129413, epsilon: 0.48201904927577055, total steps: 20304
episode:797, reward: 0.9010658890280752, mean reward: -0.11, score: -4.0236033588367945, epsilon: 0.4815153209502745, total steps: 20339
episode:798, reward: -50, mean reward: -2.03, score: -40.59992983392817, epsilon: 0.4812277399406287, total steps: 20359
episode:799, reward: 2.7139568336783384, mean reward: 0.14, score: 5.0406823917264205, epsilon: 0.4807249342710364, total steps: 20394
episode:800, reward: -50, mean reward: -0.95, score: -20.833594144594997, epsilon: 0.480409185108081, total steps: 20416
episode:801, reward: -50, mean reward: -0.71, score: -21.4154098475598, epsilon: 0.47997899105584857, total steps: 20446
episode:802, reward: 0.22617566917060117, mean reward: 0.54, score: 18.83141438047116, epsilon: 0.4794776414104426, total steps: 20481
episode:803, reward: 0.9207738441358799, mean reward: 0.2, score: 6.990189414902488, epsilon: 0.4789768763318926, total steps: 20516
episode:804, reward: -50, mean reward: -0.96, score: -31.642992544203963, epsilon: 0.47850526120380255, total steps: 20549
episode:805, reward: 0.26231575698773213, mean reward: -0.42, score: -14.594232243437062, epsilon: 0.4780056299073255, total steps: 20584
episode:806, reward: -50, mean reward: -2.4, score: -55.192095616497284, epsilon: 0.4776776180116898, total steps: 20607
episode:807, reward: -2.5860871375980423, mean reward: -0.74, score: -25.833497379760104, epsilon: 0.4771789517358986, total steps: 20642
episode:808, reward: 1.9428846623373204, mean reward: -0.14, score: -5.04777622267855, epsilon: 0.4766808668981911, total steps: 20677
episode:809, reward: -50, mean reward: -2.4, score: -52.767281247176754, epsilon: 0.47636808229750344, total steps: 20699
episode:810, reward: -50, mean reward: -5.9, score: -47.19257890882355, epsilon: 0.47625439930063074, total steps: 20707
episode:811, reward: -50, mean reward: -0.52, score: -18.105106008352692, epsilon: 0.4757573924784663, total steps: 20742
episode:812, reward: -50, mean reward: -0.86, score: -26.65154201291557, epsilon: 0.47531767040177203, total steps: 20773
episode:813, reward: -50, mean reward: -2.31, score: -34.68872793963757, epsilon: 0.4751050647224203, total steps: 20788
episode:814, reward: -0.4863256665538813, mean reward: -0.2, score: -7.067896511925625, epsilon: 0.4746093980087152, total steps: 20823
episode:815, reward: 1.2449840827063383, mean reward: 0.01, score: 0.1908660838775802, epsilon: 0.47411430923564524, total steps: 20858
episode:816, reward: -50, mean reward: -0.83, score: -20.668166475828173, epsilon: 0.4737610278656309, total steps: 20883
episode:817, reward: -50, mean reward: -0.92, score: -24.715237147076635, epsilon: 0.4733798145122927, total steps: 20910
episode:818, reward: -0.49361030794042904, mean reward: 0.62, score: 21.63152298676775, epsilon: 0.4728861594168274, total steps: 20945
episode:819, reward: 0.6284626615858144, mean reward: 0.16, score: 5.711294468567786, epsilon: 0.4723930799164776, total steps: 20980
episode:820, reward: -50, mean reward: -2.74, score: -43.80936328162625, epsilon: 0.4721678636701929, total steps: 20996
episode:821, reward: 2.0439061992578047, mean reward: 0.36, score: 12.761449610580598, epsilon: 0.4716756216928975, total steps: 21031
episode:822, reward: -50, mean reward: -4.85, score: -38.83631433895516, epsilon: 0.4715631898520244, total steps: 21039
episode:823, reward: -50, mean reward: -0.95, score: -29.465677388966185, epsilon: 0.4711277995462436, total steps: 21070
episode:824, reward: -1.3483328211879382, mean reward: -0.07, score: -2.4552698611780954, epsilon: 0.47063677026954653, total steps: 21105
episode:825, reward: 0.3435122877626213, mean reward: 1.29, score: 45.07869546099552, epsilon: 0.47014631352629616, total steps: 21140
episode:826, reward: 1.9440372705917355, mean reward: 0.07, score: 2.512089983178697, epsilon: 0.46965642864892626, total steps: 21175
episode:827, reward: -1.7507778266871412, mean reward: -0.13, score: -4.694906579493562, epsilon: 0.46916711497064906, total steps: 21210
episode:828, reward: -0.14657984259167733, mean reward: 0.3, score: 10.43825995368195, epsilon: 0.46867837182545413, total steps: 21245
episode:829, reward: -0.21279386176183834, mean reward: 0.04, score: 1.5579766325277262, epsilon: 0.46819019854810767, total steps: 21280
